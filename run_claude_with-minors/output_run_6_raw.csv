Benchmark,Website,Paper,Description,Cognitive Functions
SWE-bench Verified,https://openai.com/index/introducing-swe-bench-verified/,https://arxiv.org/abs/2310.06770,SWE-bench Verified evaluates software engineering agents on real GitHub issues where the model must generate a code patch that fixes the bug or implements the requested change and passes the repository’s tests. The “Verified” subset focuses on tasks that have been human-validated as solvable and checks correctness via deterministic test execution.,"Language Comprehension, Planning, Logical Reasoning, Adaptive Error Correction, Working Memory"
SWE-bench Multilingual,https://www.swebench.com/multilingual.html,https://arxiv.org/abs/2504.21798,"SWE-bench Multilingual extends SWE-bench-style patch generation beyond Python to multiple programming languages, testing whether agents can understand issues and modify unfamiliar codebases across language ecosystems. It emphasizes transfer of debugging and maintenance skills across different syntactic and tooling conventions.","Language Comprehension, Cognitive Flexibility, Planning, Logical Reasoning, Adaptive Error Correction, Working Memory"
SWE-bench Pro,https://scale.com/research/swe_bench_pro,https://arxiv.org/abs/2509.16941,"SWE-bench Pro is a harder, more contamination-resistant software engineering benchmark with a larger and more diverse set of tasks spanning multiple languages and more realistic industry maintenance work. Agents must plan and implement robust multi-file changes that satisfy hidden unit/integration tests.","Language Comprehension, Planning, Decision-making, Logical Reasoning, Adaptive Error Correction, Working Memory"
Terminal-Bench 2.0,https://www.tbench.ai/,,"Terminal-Bench 2.0 evaluates agent performance on real command-line tasks (e.g., debugging, building, configuring, data wrangling) executed in a sandboxed terminal environment. Success requires selecting and sequencing shell commands, interpreting outputs/errors, and iterating toward a working end state.","Planning, Decision-making, Adaptive Error Correction, Working Memory, Attention, Sensorimotor Coordination"
BrowseComp,https://openai.com/index/browsecomp/,https://arxiv.org/abs/2504.12516,"BrowseComp measures an agent’s ability to answer difficult questions by searching and synthesizing information from a controlled document collection, aiming for reproducible “browsing” evaluation. It tests whether the agent can formulate queries, gather evidence, resolve conflicts, and produce a grounded final answer.","Language Comprehension, Planning, Attention, Working Memory, Semantic Understanding & Context Recognition, Logical Reasoning"
τ2-bench,https://sierra.ai/uk/blog/benchmarking-ai-agents,https://arxiv.org/abs/2406.12045,"τ2-bench evaluates interactive tool-using agents in customer-support-like domains (e.g., retail, airline, telecom) where the model must follow policies while calling APIs and coordinating multi-turn dialogs with a simulated user. The benchmark stresses robustness to long-horizon interaction, policy adherence, and recovery from tool or user-induced complications.","Language Comprehension, Language Production, Planning, Decision-making, Social Reasoning & Theory of Mind, Inhibitory Control, Empathy, Working Memory"
OSWorld,https://os-world.github.io/,https://arxiv.org/abs/2404.07972,"OSWorld benchmarks multimodal “computer use” agents on tasks performed inside an operating-system-like environment with graphical interfaces. Models must perceive screenshots, navigate UI state, and execute multi-step actions to accomplish goals under step limits and partial observability.","Visual Perception, Scene Understanding & Visual Reasoning, Visual Attention & Eye Movements, Planning, Decision-making, Sensorimotor Coordination, Working Memory"
ARC-AGI,https://arcprize.org/arc-agi,https://arxiv.org/abs/1911.01547,"ARC-AGI tests fluid, few-shot abstraction by asking models to infer hidden transformations from a handful of input–output grid examples and then produce the correct output grid for a new input. It is designed to reduce reliance on memorized knowledge and emphasize novel pattern induction and generalization.","Logical Reasoning, Cognitive Flexibility, Working Memory, Attention, Spatial Representation & Mapping"
Vending-Bench 2,https://andonlabs.com/evals/vending-bench-2,https://arxiv.org/abs/2502.15840,"Vending-Bench 2 evaluates long-horizon autonomous agent performance by simulating operation of a vending-machine business over an extended period, scoring on final financial outcomes. Agents must make coherent sequences of decisions (pricing, inventory, supplier negotiation) while adapting to changing market conditions.","Planning, Decision-making, Working Memory, Reward Mechanisms, Adaptive Error Correction, Motivational Drives"
MCP-Atlas,https://scale.com/leaderboard/mcp_atlas,,"MCP-Atlas evaluates real-world tool use via the Model Context Protocol, requiring models to discover relevant tools, call them correctly, handle failures, and compose multi-step workflows across different MCP servers. It emphasizes dependable API interaction and integration of tool results into accurate end outputs.","Language Comprehension, Planning, Decision-making, Adaptive Error Correction, Working Memory"
FinanceAgent,https://www.vals.ai/benchmarks/finance_agent,,"FinanceAgent assesses agent performance on tasks typical of an entry-level financial analyst, such as financial modeling, analysis, and report generation, often requiring structured reasoning with domain constraints. It tests whether models can interpret financial context, execute multi-step analyses, and present decisions with supporting rationale.","Semantic Understanding & Context Recognition, Logical Reasoning, Planning, Decision-making, Language Production, Working Memory"
CyberGym,https://www.cybergym.io/,https://arxiv.org/abs/2506.02548,"CyberGym evaluates cybersecurity agents on tasks including identifying known vulnerabilities in real open-source projects from high-level descriptions and discovering new vulnerabilities. Performance depends on analyzing code and program behavior, hypothesizing weaknesses, and iteratively testing and refining findings.","Logical Reasoning, Planning, Adaptive Error Correction, Inhibitory Control, Working Memory, Attention"
SpreadsheetBench,https://spreadsheetbench.github.io/,https://arxiv.org/abs/2406.14991,"SpreadsheetBench measures an agent’s ability to work with complex spreadsheets, including reading/writing cells, transforming data, building formulas, and producing correct computed results. It probes whether models can maintain consistency across many interdependent fields and avoid cascading errors.","Logical Reasoning, Planning, Working Memory, Attention, Adaptive Error Correction"
Humanity’s Last Exam,https://agi.safe.ai/,https://arxiv.org/abs/2501.14249,"Humanity’s Last Exam is a large, frontier-oriented multimodal benchmark spanning many disciplines and including difficult questions intended to stress expert-level reasoning and breadth of knowledge. It often requires integrating text and visual inputs, handling ambiguity, and producing well-justified answers under uncertainty.","Language Comprehension, Language Production, Scene Understanding & Visual Reasoning, Visual Perception, Semantic Understanding & Context Recognition, Logical Reasoning, Working Memory, Attention"
AIME 2025,https://matharena.ai/?view=problem&comp=aime--aime_2025,https://arxiv.org/abs/2505.23281,"AIME 2025 evaluates mathematical problem solving on competition-style questions that demand multi-step derivations rather than rote recall. It tests correctness of symbolic manipulation, structured reasoning, and the ability to track intermediate constraints to reach a single numeric answer.","Logical Reasoning, Working Memory, Planning, Attention"
GPQA Diamond,https://artificialanalysis.ai/evaluations/gpqa-diamond,https://arxiv.org/abs/2311.12022,"GPQA Diamond is a subset of graduate-level, multiple-choice science questions selected to be especially resistant to superficial pattern matching and to require genuine scientific reasoning. It stresses precise reading, elimination of distractors, and integrating domain knowledge with logical inference.","Language Comprehension, Semantic Understanding & Context Recognition, Logical Reasoning, Working Memory, Attention"
MMMLU,https://huggingface.co/datasets/openai/MMMLU,https://arxiv.org/abs/2009.03300,"MMMLU extends MMLU to multilingual settings, evaluating knowledge and reasoning across many academic subjects in multiple non-English languages. It probes whether models can preserve reasoning competence while operating in different linguistic and cultural contexts.","Language Comprehension, Semantic Understanding & Context Recognition, Logical Reasoning, Working Memory, Cognitive Flexibility"
MMMU,https://mmmu-benchmark.github.io/,https://arxiv.org/abs/2311.16502,"MMMU is a multimodal benchmark spanning many disciplines where questions require interpreting images (e.g., diagrams, charts, figures) alongside text. It emphasizes grounding language in visual evidence and performing multi-step reasoning over combined modalities.","Multisensory Integration, Visual Perception, Scene Understanding & Visual Reasoning, Visual Attention & Eye Movements, Language Comprehension, Logical Reasoning, Working Memory"
LAB-Bench FigQA,https://huggingface.co/datasets/futurehouse/lab-bench,https://arxiv.org/abs/2407.10362,"LAB-Bench FigQA evaluates whether models can correctly answer questions about complex scientific figures from biology papers, including interpreting plots, annotations, and experimental schematics. It targets the kind of visual-semantic reasoning needed for practical scientific reading and figure-based inference.","Visual Perception, Scene Understanding & Visual Reasoning, Semantic Understanding & Context Recognition, Logical Reasoning, Attention, Working Memory"
WebArena,https://webarena.dev/,https://arxiv.org/abs/2307.13854,"WebArena evaluates autonomous web agents on realistic multi-step tasks across several web applications (e-commerce, forums, CMS, code hosting, maps) using a browser-like interface. Models must navigate dynamic pages, fill forms, follow task constraints, and recover from mistakes over long interaction sequences.","Planning, Decision-making, Visual Perception, Scene Understanding & Visual Reasoning, Visual Attention & Eye Movements, Sensorimotor Coordination, Working Memory, Language Comprehension"
