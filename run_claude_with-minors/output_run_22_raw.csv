Benchmark,Website,Paper,Description,Cognitive Functions
SWE-bench Verified,https://openai.com/index/introducing-swe-bench-verified/,https://arxiv.org/abs/2310.06770,"SWE-bench Verified evaluates models on real GitHub issues that require producing a correct code patch in a Python repository. The “Verified” subset consists of tasks that have been confirmed by human review to be solvable and to have reliable, test-based grading, emphasizing end-to-end bug fixing and feature implementation.","Language Comprehension, Planning, Decision-making, Logical Reasoning, Adaptive Error Correction, Working Memory"
SWE-bench Multilingual,https://www.swebench.com/multilingual.html,https://arxiv.org/abs/2504.21798,"SWE-bench Multilingual extends the SWE-bench format beyond Python to multiple programming languages, testing whether a model can diagnose and repair issues across diverse ecosystems. It stresses robust code reasoning under varying syntax, tooling conventions, and library idioms while still requiring an executable patch that passes tests.","Language Comprehension, Cognitive Flexibility, Planning, Decision-making, Logical Reasoning, Adaptive Error Correction, Working Memory"
SWE-bench Pro,https://scale.com/research/swe_bench_pro,https://arxiv.org/abs/2509.16941,"SWE-bench Pro is a larger and more difficult software engineering benchmark designed to be more realistic and contamination-resistant, spanning multiple languages and industrial-style tasks. It emphasizes longer-horizon debugging and implementation, where models must select strategies, manage context, and iteratively converge on a correct solution under strict evaluation.","Language Comprehension, Planning, Decision-making, Logical Reasoning, Adaptive Error Correction, Working Memory"
Terminal-Bench 2.0,https://www.tbench.ai/,,"Terminal-Bench 2.0 measures how well an agent can complete real tasks in a command-line environment, such as configuring tools, manipulating files, running programs, and troubleshooting failures. Success depends on issuing correct sequences of terminal commands and adapting when outputs, errors, or environment constraints change.","Planning, Decision-making, Adaptive Error Correction, Working Memory, Language Comprehension"
BrowseComp,https://openai.com/index/browsecomp/,https://arxiv.org/abs/2504.12516,"BrowseComp evaluates deep-research style question answering where a model must use web browsing/search to locate and synthesize evidence for hard queries. It probes the ability to plan an investigation, extract relevant facts from sources, and maintain coherence while integrating information across multiple documents.","Planning, Decision-making, Language Comprehension, Semantic Understanding & Context Recognition, Working Memory, Episodic Memory"
τ2-bench,https://sierra.ai/uk/blog/benchmarking-ai-agents,https://arxiv.org/abs/2406.12045,"τ2-bench (Tau2-bench) evaluates interactive tool-using agents in multi-turn customer support scenarios with policies, constraints, and simulated users. The agent must follow domain rules, call APIs correctly, and manage conversational state while balancing helpfulness and compliance.","Language Comprehension, Language Production, Social Reasoning & Theory of Mind, Inhibitory Control, Decision-making, Planning, Working Memory"
OSWorld,https://os-world.github.io/,https://arxiv.org/abs/2404.07972,"OSWorld tests multimodal “computer use” agents that must complete tasks on a real or realistic operating system desktop using screenshots and action interfaces (e.g., clicks, typing). It measures perception-to-action competence: interpreting UI state, navigating applications, and executing multi-step procedures reliably.","Visual Perception, Visual Attention & Eye Movements, Sensorimotor Coordination, Planning, Decision-making, Working Memory, Adaptive Error Correction"
ARC-AGI,https://arcprize.org/arc-agi,https://arxiv.org/abs/1911.01547,"ARC-AGI measures abstract pattern discovery and generalization from a few examples using grid-based input-output tasks. Models must infer latent rules and apply them to novel instances, emphasizing flexible reasoning rather than memorized domain knowledge.","Logical Reasoning, Cognitive Flexibility, Working Memory, Spatial Representation & Mapping, Attention"
Vending-Bench 2,https://andonlabs.com/evals/vending-bench-2,https://arxiv.org/abs/2502.15840,"Vending-Bench 2 evaluates long-horizon autonomous agent performance in a simulated business setting, where the agent manages a vending machine operation over an extended period. It requires sustained strategy, resource management, adaptation to changing conditions, and coherent decision-making across many steps.","Planning, Decision-making, Reward Mechanisms, Working Memory, Episodic Memory, Adaptive Error Correction, Self-reflection"
MCP-Atlas,https://scale.com/leaderboard/mcp_atlas,,"MCP-Atlas benchmarks real-world tool use via the Model Context Protocol, requiring models to discover tools, call them with correct arguments, handle errors, and combine outputs into a final answer. It emphasizes multi-step workflow execution across heterogeneous services, closer to production integration than toy tool-use tasks.","Planning, Decision-making, Adaptive Error Correction, Working Memory, Language Comprehension"
FinanceAgent,https://www.vals.ai/benchmarks/finance_agent,,"FinanceAgent evaluates agent performance on tasks typical of entry-level financial analysis, such as interpreting financial documents, building analyses, and producing structured outputs with appropriate assumptions. It stresses numeracy and domain reasoning while also requiring careful synthesis and consistency across multi-part deliverables.","Logical Reasoning, Semantic Understanding & Context Recognition, Planning, Decision-making, Working Memory, Language Comprehension"
CyberGym,https://www.cybergym.io/,https://arxiv.org/abs/2506.02548,"CyberGym evaluates AI agents on cybersecurity tasks at scale, including identifying known vulnerabilities and discovering new ones in real open-source projects. It emphasizes systematic exploration, precise technical reasoning, and iterative debugging in adversarially complex codebases and environments.","Logical Reasoning, Planning, Decision-making, Adaptive Error Correction, Working Memory, Language Comprehension"
SpreadsheetBench,https://spreadsheetbench.github.io/,https://arxiv.org/abs/2406.14991,"SpreadsheetBench measures an agent’s ability to navigate, edit, and compute with complex spreadsheets, often requiring formula creation, data transformation, and multi-sheet consistency. The benchmark stresses executing structured operations correctly while maintaining bookkeeping-like accuracy across many cells and constraints.","Planning, Decision-making, Logical Reasoning, Working Memory, Adaptive Error Correction"
Humanity’s Last Exam,https://agi.safe.ai/,https://arxiv.org/abs/2501.14249,"Humanity’s Last Exam is a difficult, expert-facing benchmark spanning many domains, designed to test frontier reasoning and knowledge and, in some settings, multimodal understanding. Tasks often require integrating scattered evidence, performing multi-step inference, and resisting shallow pattern-matching on unfamiliar questions.","Language Comprehension, Logical Reasoning, Semantic Understanding & Context Recognition, Working Memory, Scene Understanding & Visual Reasoning, Visual Perception"
AIME 2025,https://matharena.ai/?view=problem&comp=aime--aime_2025,https://arxiv.org/abs/2505.23281,"AIME 2025 consists of competition-style math problems requiring multi-step derivations and exact numeric answers. It probes symbolic and quantitative reasoning under tight problem statements, where small logical slips can invalidate the final result.","Logical Reasoning, Working Memory, Planning, Attention"
GPQA Diamond,https://artificialanalysis.ai/evaluations/gpqa-diamond,https://arxiv.org/abs/2311.12022,"GPQA Diamond is a high-quality subset of graduate-level, “Google-proof” science multiple-choice questions curated to be difficult for non-experts. It emphasizes deep conceptual understanding and careful elimination reasoning rather than surface recall.","Language Comprehension, Logical Reasoning, Semantic Understanding & Context Recognition, Working Memory, Decision-making"
MMMLU,https://huggingface.co/datasets/openai/MMMLU,https://arxiv.org/abs/2009.03300,"MMMLU extends MMLU to multiple languages, testing knowledge and reasoning across many subjects under multilingual prompts. It evaluates whether models can transfer conceptual understanding across languages and maintain consistent performance under linguistic variation.","Language Comprehension, Semantic Understanding & Context Recognition, Logical Reasoning, Cognitive Flexibility, Working Memory"
MMMU,https://mmmu-benchmark.github.io/,https://arxiv.org/abs/2311.16502,"MMMU is a multimodal benchmark covering many disciplines where questions require jointly reasoning over images and text (e.g., diagrams, charts, and technical figures). It tests visual interpretation, cross-modal grounding, and multi-step reasoning to arrive at precise answers.","Multisensory Integration, Visual Perception, Scene Understanding & Visual Reasoning, Language Comprehension, Logical Reasoning, Working Memory, Attention"
LAB-Bench FigQA,https://huggingface.co/datasets/futurehouse/lab-bench,https://arxiv.org/abs/2407.10362,LAB-Bench FigQA evaluates whether models can correctly interpret complex scientific figures from biology papers and answer questions grounded in those visuals. It stresses extracting quantitative/relational information from plots and schematics and mapping it to domain-specific scientific claims.,"Visual Perception, Scene Understanding & Visual Reasoning, Language Comprehension, Semantic Understanding & Context Recognition, Logical Reasoning, Working Memory"
WebArena,https://webarena.dev/,https://arxiv.org/abs/2307.13854,"WebArena evaluates autonomous web agents on realistic tasks across multiple web applications (e-commerce, CMS, forums, code hosting, maps), requiring navigation and form-based interactions. It probes end-to-end planning and action selection under dynamic page states, with error recovery when earlier actions lead to dead ends.","Planning, Decision-making, Adaptive Error Correction, Working Memory, Language Comprehension, Visual Perception, Sensorimotor Coordination, Attention"
