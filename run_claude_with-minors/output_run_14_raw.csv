Benchmark,Website,Paper,Description,Cognitive Functions
SWE-bench Verified,https://openai.com/index/introducing-swe-bench-verified/,https://arxiv.org/abs/2310.06770,"SWE-bench Verified evaluates agentic software engineering by asking a model to produce a patch that fixes real issues in open-source Python repositories, validated by running the project’s tests. The “Verified” subset consists of tasks that have been manually confirmed to be solvable and correctly specified, emphasizing reliable end-to-end bug fixing over toy coding.","Planning, Decision-making, Logical Reasoning, Adaptive Error Correction, Working Memory, Language Comprehension, Language Production, Semantic Understanding & Context Recognition"
SWE-bench Multilingual,https://www.swebench.com/multilingual.html,https://arxiv.org/abs/2504.21798,"SWE-bench Multilingual extends SWE-bench-style repository patching to multiple programming languages, assessing whether a model can understand unfamiliar codebases and toolchains beyond Python. It emphasizes robust cross-language debugging, patch generation, and test-driven validation under realistic repo constraints.","Planning, Decision-making, Logical Reasoning, Adaptive Error Correction, Working Memory, Language Comprehension, Language Production, Cognitive Flexibility, Semantic Understanding & Context Recognition"
SWE-bench Pro,https://scale.com/research/swe_bench_pro,https://arxiv.org/abs/2509.16941,"SWE-bench Pro is a larger and more difficult software engineering benchmark designed to be more industrially relevant and contamination-resistant, spanning multiple languages and more complex issues. It tests whether a model can navigate larger repositories, interpret failing tests and logs, and deliver correct patches under stricter evaluation conditions.","Planning, Decision-making, Logical Reasoning, Adaptive Error Correction, Working Memory, Language Comprehension, Language Production, Cognitive Flexibility, Semantic Understanding & Context Recognition"
Terminal-Bench 2.0,https://www.tbench.ai/,,"Terminal-Bench 2.0 evaluates real-world command-line task completion in isolated environments, requiring models to inspect files, run commands, interpret outputs, and iteratively refine actions. It focuses on practical “computer use” through a terminal, where success depends on correct sequencing, debugging, and state tracking across steps.","Planning, Decision-making, Adaptive Error Correction, Working Memory, Semantic Understanding & Context Recognition, Inhibitory Control, Cognitive Flexibility"
BrowseComp,https://openai.com/index/browsecomp/,https://arxiv.org/abs/2504.12516,"BrowseComp evaluates deep research and browsing competence using a controlled document set, where models must search, read, synthesize evidence, and produce grounded answers. It stresses tool-augmented information seeking, long-horizon planning of queries, and integrating multiple sources while avoiding unsupported claims.","Planning, Decision-making, Attention, Semantic Understanding & Context Recognition, Episodic Memory, Working Memory, Language Comprehension, Language Production"
τ2-bench,https://sierra.ai/uk/blog/benchmarking-ai-agents,https://arxiv.org/abs/2406.12045,"τ2-bench measures an agent’s ability to handle multi-turn customer-support scenarios while calling tools/APIs and adhering to domain policies (e.g., retail, airline, telecom). It emphasizes policy-following behavior in interactive contexts, including correct tool selection, consistent state updates, and resolving ambiguous user goals.","Social Reasoning & Theory of Mind, Empathy, Inhibitory Control, Planning, Decision-making, Working Memory, Language Comprehension, Language Production, Adaptive Error Correction, Reward Mechanisms"
OSWorld,https://os-world.github.io/,https://arxiv.org/abs/2404.07972,"OSWorld evaluates multimodal computer-use agents on realistic operating system tasks, requiring interaction with GUI elements, application workflows, and multi-step procedures. Models must perceive screens, decide actions, and execute long sequences reliably while tracking progress and recovering from errors.","Visual Perception, Visual Attention & Eye Movements, Scene Understanding & Visual Reasoning, Planning, Decision-making, Working Memory, Spatial Representation & Mapping, Sensorimotor Coordination, Adaptive Error Correction"
ARC-AGI,https://arcprize.org/arc-agi,https://arxiv.org/abs/1911.01547,ARC-AGI tests few-shot abstract reasoning on grid-based puzzles where the rule must be inferred from only a handful of input–output examples. It is designed to probe generalization to novel patterns and transformations rather than memorized domain knowledge.,"Logical Reasoning, Working Memory, Cognitive Flexibility, Attention, Spatial Representation & Mapping, Scene Understanding & Visual Reasoning, Planning"
Vending-Bench 2,https://andonlabs.com/evals/vending-bench-2,https://arxiv.org/abs/2502.15840,"Vending-Bench 2 evaluates long-horizon autonomy by having an agent run a simulated vending-machine business over many decisions, optimizing inventory, pricing, procurement, and strategy. Performance depends on maintaining coherent goals across time, adapting to market dynamics, and learning from feedback signals like profit and stockouts.","Planning, Decision-making, Working Memory, Episodic Memory, Reward Mechanisms, Adaptive Error Correction, Motivational Drives, Self-reflection"
MCP-Atlas,https://scale.com/leaderboard/mcp_atlas,,"MCP-Atlas evaluates real-world tool use via the Model Context Protocol, requiring models to discover appropriate tools, invoke them correctly, handle errors, and synthesize results into accurate answers. Tasks typically require multi-step workflows across heterogeneous servers/APIs, emphasizing robust orchestration over single-call tool usage.","Planning, Decision-making, Working Memory, Semantic Understanding & Context Recognition, Adaptive Error Correction, Cognitive Flexibility, Language Comprehension, Language Production"
FinanceAgent,https://www.vals.ai/benchmarks/finance_agent,,"FinanceAgent assesses performance on tasks typical of an entry-level financial analyst, such as interpreting financial documents, performing calculations, and producing structured analyses or models. It probes applied reasoning under domain constraints, where correctness depends on grounding in provided data and consistent assumptions.","Logical Reasoning, Planning, Decision-making, Working Memory, Semantic Understanding & Context Recognition, Adaptive Error Correction, Language Comprehension, Language Production"
CyberGym,https://www.cybergym.io/,https://arxiv.org/abs/2506.02548,"CyberGym evaluates cybersecurity agent capabilities on large-scale tasks involving finding known vulnerabilities and discovering previously unknown ones in real software projects. It requires interpreting vulnerability descriptions, navigating codebases, reproducing issues, and proposing fixes or exploits under realistic constraints.","Logical Reasoning, Planning, Decision-making, Adaptive Error Correction, Working Memory, Semantic Understanding & Context Recognition, Cognitive Flexibility, Inhibitory Control"
SpreadsheetBench,https://spreadsheetbench.github.io/,https://arxiv.org/abs/2406.14991,"SpreadsheetBench measures the ability to understand, edit, and compute with complex spreadsheets, including multi-sheet dependencies and real-world formatting/logic. Success requires mapping goals to precise operations, tracking intermediate values, and validating outputs against constraints.","Working Memory, Planning, Decision-making, Logical Reasoning, Adaptive Error Correction, Semantic Understanding & Context Recognition, Attention"
Humanity’s Last Exam,https://agi.safe.ai/,https://arxiv.org/abs/2501.14249,"Humanity’s Last Exam is a challenging multimodal benchmark spanning frontier questions across many domains, designed to test advanced reasoning, knowledge integration, and (when enabled) tool-assisted problem solving. It stresses careful interpretation, synthesis, and the ability to avoid hallucinated justifications when evidence is limited.","Language Comprehension, Language Production, Logical Reasoning, Semantic Understanding & Context Recognition, Working Memory, Attention, Visual Perception, Scene Understanding & Visual Reasoning"
AIME 2025,https://matharena.ai/?view=problem&comp=aime--aime_2025,https://arxiv.org/abs/2505.23281,"AIME 2025 evaluates competition-level mathematical problem solving using short, high-difficulty questions that require multi-step derivations and precision. It rewards robust symbolic manipulation, structured reasoning, and checking of intermediate steps under tight problem specifications.","Logical Reasoning, Working Memory, Planning, Adaptive Error Correction, Attention"
GPQA Diamond,https://artificialanalysis.ai/evaluations/gpqa-diamond,https://arxiv.org/abs/2311.12022,GPQA Diamond is a subset of GPQA consisting of especially difficult graduate-level multiple-choice science questions designed to be resistant to simple web lookup. It tests deep scientific understanding and careful reasoning under distractors where superficial pattern matching often fails.,"Logical Reasoning, Semantic Understanding & Context Recognition, Working Memory, Attention, Decision-making"
MMMLU,https://huggingface.co/datasets/openai/MMMLU,https://arxiv.org/abs/2009.03300,MMMLU is a multilingual extension of MMLU that measures broad academic knowledge and reasoning across many subjects in numerous languages. It emphasizes cross-lingual comprehension and consistent conceptual reasoning despite linguistic variation.,"Language Comprehension, Semantic Understanding & Context Recognition, Logical Reasoning, Working Memory, Cognitive Flexibility, Attention"
MMMU,https://mmmu-benchmark.github.io/,https://arxiv.org/abs/2311.16502,"MMMU evaluates multimodal expert-level understanding across many disciplines, requiring models to answer questions that combine text with images such as diagrams, plots, and technical figures. It stresses integrating visual evidence with domain knowledge and reasoning to select or generate correct answers.","Visual Perception, Scene Understanding & Visual Reasoning, Multisensory Integration, Language Comprehension, Logical Reasoning, Working Memory, Attention, Spatial Representation & Mapping"
LAB-Bench FigQA,https://huggingface.co/datasets/futurehouse/lab-bench,https://arxiv.org/abs/2407.10362,"LAB-Bench FigQA evaluates whether models can correctly interpret complex biology paper figures, including extracting trends, comparing conditions, and drawing mechanistic conclusions from visual evidence. It focuses on scientific visual reasoning grounded in figure content rather than general image captioning.","Visual Perception, Scene Understanding & Visual Reasoning, Semantic Understanding & Context Recognition, Logical Reasoning, Working Memory, Attention, Language Comprehension, Language Production"
WebArena,https://webarena.dev/,https://arxiv.org/abs/2307.13854,"WebArena evaluates autonomous web agents on realistic tasks across multiple web apps (e-commerce, CMS, forums, code hosting, maps), requiring navigation, form filling, and multi-step workflows. It measures long-horizon planning and robustness to dynamic interfaces, including recovering from mistakes and ambiguities in web state.","Planning, Decision-making, Working Memory, Adaptive Error Correction, Visual Perception, Visual Attention & Eye Movements, Semantic Understanding & Context Recognition, Cognitive Flexibility, Social Reasoning & Theory of Mind"
