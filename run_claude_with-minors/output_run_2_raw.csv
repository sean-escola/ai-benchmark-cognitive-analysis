Benchmark,Website,Paper,Description,Cognitive Functions
SWE-bench Verified,https://openai.com/index/introducing-swe-bench-verified/,https://arxiv.org/abs/2310.06770,"SWE-bench Verified evaluates software engineering agents on real, issue-style tasks drawn from GitHub repositories. The model must produce a patch that makes tests pass, with the “Verified” subset curated to ensure tasks are solvable and correctly specified by human verification.","Language Comprehension, Logical Reasoning, Planning, Working Memory, Adaptive Error Correction"
Terminal-Bench 2.0,https://www.tbench.ai/,,"Terminal-Bench 2.0 tests agentic performance in command-line environments where the model must accomplish practical tasks by executing shell commands and manipulating files. Success typically requires iteratively inspecting outputs, debugging failures, and adjusting actions under resource constraints.","Planning, Decision-making, Adaptive Error Correction, Working Memory, Language Comprehension"
BrowseComp,https://openai.com/index/browsecomp/,https://arxiv.org/abs/2504.12516,"BrowseComp evaluates deep-research style question answering where models must search, read, and synthesize information from the web (or a controlled corpus, depending on the setup). The benchmark emphasizes multi-step information gathering, source tracking, and producing grounded final answers.","Planning, Attention, Semantic Understanding & Context Recognition, Working Memory, Language Comprehension, Language Production"
τ2-bench,https://sierra.ai/uk/blog/benchmarking-ai-agents,https://arxiv.org/abs/2406.12045,"τ2-bench measures how well an agent handles multi-turn customer-support scenarios by interacting with simulated users and external APIs while following domain policies. It stresses reliable tool use, policy adherence, and coherent dialogue over long interactions.","Language Comprehension, Language Production, Decision-making, Planning, Inhibitory Control, Social Reasoning & Theory of Mind, Working Memory"
OSWorld,https://os-world.github.io/,https://arxiv.org/abs/2404.07972,"OSWorld benchmarks multimodal computer-use agents operating in desktop-like OS environments to complete realistic tasks via GUI interactions. Models must perceive screenshots, navigate interfaces, and execute multi-step procedures robustly across applications.","Visual Perception, Visual Attention & Eye Movements, Planning, Decision-making, Sensorimotor Coordination, Working Memory"
ARC-AGI,https://arcprize.org/arc-agi,https://arxiv.org/abs/1911.01547,ARC-AGI tests fluid reasoning via grid-based pattern induction: the model infers hidden rules from a few input-output examples and applies them to a new input. It is designed to minimize reliance on memorized knowledge and emphasize novel problem solving.,"Logical Reasoning, Cognitive Flexibility, Working Memory, Spatial Representation & Mapping, Visual Perception, Attention"
Vending-Bench 2,https://andonlabs.com/evals/vending-bench-2,https://arxiv.org/abs/2502.15840,"Vending-Bench 2 evaluates long-horizon autonomy by having an agent run a simulated vending-machine business over many steps, aiming to maximize final balance. High performance requires sustained coherence, strategic planning, and adaptation to changing market conditions.","Planning, Decision-making, Reward Mechanisms, Working Memory, Adaptive Error Correction, Self-reflection"
MCP-Atlas,https://scale.com/leaderboard/mcp_atlas,,"MCP-Atlas evaluates real-world tool use through the Model Context Protocol, where models must discover, call, and compose tools across multi-step workflows. Tasks emphasize correct parameterization, error handling, and synthesizing tool results into accurate outputs.","Planning, Decision-making, Adaptive Error Correction, Working Memory, Language Comprehension, Language Production"
FinanceAgent,https://www.vals.ai/benchmarks/finance_agent,,"FinanceAgent assesses performance on tasks resembling entry-level financial analyst work, such as analyzing filings, building or checking models, and producing decision-ready written outputs. It emphasizes domain knowledge, quantitative reasoning, and structured communication.","Semantic Understanding & Context Recognition, Logical Reasoning, Planning, Decision-making, Working Memory, Language Production"
CyberGym,https://www.cybergym.io/,https://arxiv.org/abs/2506.02548,"CyberGym evaluates cybersecurity agents on tasks involving identifying known vulnerabilities from descriptions and discovering new vulnerabilities in real software. The benchmark stresses code understanding, exploit reasoning, and systematic debugging or search strategies.","Logical Reasoning, Planning, Adaptive Error Correction, Working Memory, Semantic Understanding & Context Recognition, Attention"
SpreadsheetBench,https://spreadsheetbench.github.io/,https://arxiv.org/abs/2406.14991,"SpreadsheetBench measures an agent’s ability to read, modify, and compute with complex spreadsheets using realistic tasks and tooling. Success requires accurate formula reasoning, careful manipulation, and verification of outputs against task requirements.","Logical Reasoning, Planning, Decision-making, Working Memory, Adaptive Error Correction, Semantic Understanding & Context Recognition"
Humanity’s Last Exam,https://agi.safe.ai/,https://arxiv.org/abs/2501.14249,"Humanity’s Last Exam is a difficult, multimodal benchmark spanning frontier academic and professional questions intended to stress broad knowledge and reasoning. Tasks often require integrating textual and visual information and producing high-precision answers under uncertainty.","Language Comprehension, Language Production, Logical Reasoning, Semantic Understanding & Context Recognition, Working Memory, Visual Perception, Scene Understanding & Visual Reasoning"
AIME 2025,https://matharena.ai/?view=problem&comp=aime--aime_2025,https://arxiv.org/abs/2505.23281,"AIME 2025 evaluates competition-style mathematics problem solving, typically requiring multi-step derivations and precise final numeric answers. It emphasizes symbolic manipulation, careful constraint handling, and error checking.","Logical Reasoning, Working Memory, Adaptive Error Correction, Planning"
GPQA Diamond,https://artificialanalysis.ai/evaluations/gpqa-diamond,https://arxiv.org/abs/2311.12022,"GPQA Diamond is a high-quality subset of graduate-level science multiple-choice questions designed to be difficult to answer via superficial recall. It targets deep reasoning over specialized knowledge across physics, chemistry, and biology.","Semantic Understanding & Context Recognition, Logical Reasoning, Working Memory, Inhibitory Control"
MMMLU,https://huggingface.co/datasets/openai/MMMLU,https://arxiv.org/abs/2009.03300,"MMMLU extends broad academic evaluation across many subjects into multiple languages, testing whether models retain capability beyond English. It probes multilingual knowledge and reasoning consistency across varied linguistic contexts.","Language Comprehension, Semantic Understanding & Context Recognition, Working Memory, Logical Reasoning"
MMMU,https://mmmu-benchmark.github.io/,https://arxiv.org/abs/2311.16502,"MMMU is a multimodal benchmark requiring expert-level understanding and reasoning over images paired with text across many disciplines. Questions often involve interpreting diagrams, plots, or figures and selecting or producing correct answers.","Visual Perception, Scene Understanding & Visual Reasoning, Multisensory Integration, Language Comprehension, Logical Reasoning, Working Memory, Attention"
LAB-Bench FigQA,https://huggingface.co/datasets/futurehouse/lab-bench,https://arxiv.org/abs/2407.10362,"LAB-Bench FigQA focuses on scientific-figure question answering, requiring models to extract and reason about information in biology paper figures. It tests whether agents can correctly interpret complex visual evidence and connect it to scientific queries.","Visual Perception, Scene Understanding & Visual Reasoning, Language Comprehension, Logical Reasoning, Attention, Working Memory"
CharXiv Reasoning,https://charxiv.github.io/,https://arxiv.org/abs/2406.18521,"CharXiv Reasoning evaluates reasoning over scientific artifacts drawn from arXiv-style content, emphasizing figure/chart-centric understanding and justification. It stresses extracting quantitative or relational information from visuals and integrating it with text context.","Visual Perception, Scene Understanding & Visual Reasoning, Logical Reasoning, Working Memory, Language Comprehension, Attention"
Video-MMMU,https://videommmu.github.io/,https://arxiv.org/abs/2501.13826,"Video-MMMU extends multimodal understanding to temporal video inputs, requiring models to track events, interpret actions, and answer questions grounded in sequences of frames. It emphasizes temporal integration and maintaining consistency over long visual contexts.","Visual Perception, Scene Understanding & Visual Reasoning, Attention, Working Memory, Episodic Memory, Cognitive Timing & Predictive Modeling, Multisensory Integration"
FACTS Benchmark Suite,https://deepmind.google/blog/facts-benchmark-suite-systematically-evaluating-the-factuality-of-large-language-models/,https://arxiv.org/abs/2512.10791,"The FACTS Benchmark Suite systematically evaluates factuality by measuring whether model outputs are supported by provided sources or known references across diverse settings. It targets hallucination reduction, accurate attribution, and reliable grounding under prompting variation.","Semantic Understanding & Context Recognition, Language Production, Inhibitory Control, Self-reflection, Working Memory, Attention"
Global PIQA,https://huggingface.co/datasets/mrlbenchmarks/global-piqa-nonparallel,https://arxiv.org/abs/2510.24081,"Global PIQA evaluates physical commonsense and practical reasoning across languages, focusing on what actions or solutions are plausible in everyday situations. It stresses grounding in intuitive physics and constraints, while maintaining multilingual robustness.","Logical Reasoning, Semantic Understanding & Context Recognition, Spatial Representation & Mapping, Language Comprehension, Working Memory"
MRCR v2 (8-needle),https://huggingface.co/datasets/openai/mrcr,https://arxiv.org/abs/2409.12640,"MRCR v2 (8-needle) is a long-context coreference/retrieval-style evaluation where multiple similar “needle” requests are embedded in a long “haystack,” and the model must reproduce the correct response for a specified needle. It probes accurate long-range dependency tracking under distractors.","Working Memory, Attention, Episodic Memory, Language Comprehension, Adaptive Error Correction"
GDPval,https://openai.com/index/gdpval/,https://arxiv.org/abs/2510.04374,"GDPval measures performance on economically relevant, well-specified knowledge-work tasks (e.g., producing business artifacts like spreadsheets or presentations) judged against professional outputs. It emphasizes end-to-end task execution quality, including planning, correctness, and communication.","Planning, Decision-making, Language Production, Semantic Understanding & Context Recognition, Working Memory, Social Reasoning & Theory of Mind, Adaptive Error Correction"
Graphwalks,https://huggingface.co/datasets/openai/graphwalks,,"Graphwalks evaluates algorithmic reasoning over graph-structured data, such as following paths, parents, or BFS-like traversals in large contexts. It tests whether models can reliably execute multi-step symbolic procedures without losing state.","Logical Reasoning, Working Memory, Attention, Spatial Representation & Mapping, Planning"
Toolathon,https://toolathlon.xyz,https://arxiv.org/abs/2510.25726,"Toolathon evaluates general tool-use competence across a broad set of APIs and multi-step workflows, emphasizing selecting the right tools and composing them correctly. It stresses robustness to tool errors, partial observability, and long action sequences.","Planning, Decision-making, Adaptive Error Correction, Working Memory, Language Comprehension, Language Production"
FrontierMath,https://epoch.ai/frontiermath,https://arxiv.org/abs/2411.04872,"FrontierMath is a difficult mathematics benchmark targeting expert-level reasoning beyond standard competition problems, often requiring novel multi-step derivations. It is designed to stress reliability on hard math, including verification and avoiding subtle logical errors.","Logical Reasoning, Working Memory, Planning, Adaptive Error Correction, Cognitive Flexibility"
