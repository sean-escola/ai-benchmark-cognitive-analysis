Benchmark,Website,Paper,Description,Cognitive Functions
SWE-bench Verified,https://openai.com/index/introducing-swe-bench-verified/,https://arxiv.org/abs/2310.06770,"SWE-bench Verified evaluates whether a model can solve real GitHub issue tasks by producing a correct patch that passes repository tests. It emphasizes realistic codebase navigation, debugging, and implementing changes under a single-attempt constraint in many reports.","Planning, Adaptive Error Correction, Working Memory, Semantic Understanding & Context Recognition, Logical Reasoning, Language Comprehension"
Terminal-Bench 2.0,https://www.tbench.ai/,,"Terminal-Bench 2.0 measures agent performance on end-to-end command-line tasks inside a real terminal environment, where the model must decide commands, inspect outputs, and iteratively fix errors. It stresses tool-mediated problem solving under resource and time constraints.","Planning, Decision-making, Adaptive Error Correction, Working Memory, Semantic Understanding & Context Recognition, Inhibitory Control"
BrowseComp,https://openai.com/index/browsecomp/,https://arxiv.org/abs/2504.12516,"BrowseComp evaluates deep research and browsing agents by requiring them to locate and synthesize answers from a fixed or controlled web/document corpus using search and retrieval tools. Success depends on decomposing ambiguous information needs into queries, verifying evidence, and composing a grounded response.","Planning, Decision-making, Attention, Working Memory, Semantic Understanding & Context Recognition, Language Production"
τ2-bench,https://sierra.ai/uk/blog/benchmarking-ai-agents,https://arxiv.org/abs/2406.12045,"τ2-bench evaluates interactive customer-support agents operating in simulated domains (e.g., retail, airline, telecom) with policies and APIs, requiring multi-turn tool use and adherence to rules. It probes the ability to follow constraints while helping a user through long, branching dialogues.","Social Reasoning & Theory of Mind, Decision-making, Planning, Inhibitory Control, Language Comprehension, Language Production"
OSWorld,https://os-world.github.io/,https://arxiv.org/abs/2404.07972,"OSWorld tests multimodal computer-use agents on real operating-system tasks (GUI navigation, app workflows, file operations) with step limits and screen observations. It stresses visual grounding, sequential control, and robust error recovery when UI states change unexpectedly.","Visual Perception, Visual Attention & Eye Movements, Sensorimotor Coordination, Planning, Decision-making, Adaptive Error Correction"
ARC-AGI,https://arcprize.org/arc-agi,https://arxiv.org/abs/1911.01547,ARC-AGI measures fluid reasoning by asking models to infer abstract transformation rules from a few grid-based input–output examples and apply them to a novel input. It targets generalization to new concepts rather than memorized domain knowledge.,"Logical Reasoning, Working Memory, Cognitive Flexibility, Spatial Representation & Mapping, Planning"
Vending-Bench 2,https://andonlabs.com/evals/vending-bench-2,https://arxiv.org/abs/2502.15840,"Vending-Bench 2 evaluates long-horizon autonomous agency by having a model run a simulated vending-machine business over an extended period, making many interconnected decisions. It requires sustained strategy, adaptation to market dynamics, and coherent bookkeeping over time.","Planning, Decision-making, Reward Mechanisms, Working Memory, Adaptive Error Correction, Self-reflection"
MCP-Atlas,https://scale.com/leaderboard/mcp_atlas,,"MCP-Atlas evaluates real-world tool use through the Model Context Protocol by testing whether a model can discover tools, invoke them correctly, and chain multiple calls into a successful workflow. It emphasizes API literacy, multi-step execution, and recovery from tool errors.","Planning, Decision-making, Adaptive Error Correction, Working Memory, Semantic Understanding & Context Recognition"
FinanceAgent,https://www.vals.ai/benchmarks/finance_agent,,"FinanceAgent assesses performance on tasks representative of an entry-level financial analyst, such as analysis, modeling, and producing finance-oriented deliverables. It stresses multi-step quantitative reasoning, structured reporting, and consistency with provided data and assumptions.","Logical Reasoning, Planning, Decision-making, Working Memory, Semantic Understanding & Context Recognition, Language Production"
CyberGym,https://www.cybergym.io/,https://arxiv.org/abs/2506.02548,"CyberGym evaluates cybersecurity agents on tasks involving finding known vulnerabilities and discovering new ones in real open-source projects from natural-language descriptions and code contexts. It probes secure reasoning, exploit-relevant debugging, and iterative hypothesis testing.","Logical Reasoning, Planning, Adaptive Error Correction, Working Memory, Inhibitory Control"
SpreadsheetBench,https://spreadsheetbench.github.io/,https://arxiv.org/abs/2406.14991,"SpreadsheetBench tests an agent’s ability to understand, manipulate, and generate complex spreadsheets based on realistic tasks (e.g., cleaning, formula editing, restructuring, analysis). It emphasizes precise multi-step operations and verification of outputs against requirements.","Working Memory, Planning, Adaptive Error Correction, Logical Reasoning, Semantic Understanding & Context Recognition"
Humanity’s Last Exam,https://agi.safe.ai/,https://arxiv.org/abs/2501.14249,"Humanity’s Last Exam is a large, multi-modal benchmark designed to probe frontier-level reasoning and knowledge across diverse subjects, often requiring synthesis and careful reading. In tool-enabled settings, it also tests whether agents can search, compute, and ground answers reliably.","Language Comprehension, Visual Perception, Logical Reasoning, Semantic Understanding & Context Recognition, Working Memory, Planning"
AIME 2025,https://matharena.ai/?view=problem&comp=aime--aime_2025,https://arxiv.org/abs/2505.23281,"AIME 2025 evaluates competition-style mathematics problem solving, typically requiring multi-step derivations and exact final answers. It focuses on symbolic reasoning, maintaining intermediate constraints, and avoiding arithmetic slips.","Logical Reasoning, Working Memory, Adaptive Error Correction, Cognitive Flexibility"
GPQA Diamond,https://artificialanalysis.ai/evaluations/gpqa-diamond,https://arxiv.org/abs/2311.12022,GPQA Diamond is a challenging multiple-choice science benchmark curated to be hard for non-experts and resistant to shallow pattern matching. It stresses deep reading of technical questions and disciplined elimination of distractor answers.,"Language Comprehension, Logical Reasoning, Semantic Understanding & Context Recognition, Working Memory, Inhibitory Control"
MMMLU,https://huggingface.co/datasets/openai/MMMLU,https://arxiv.org/abs/2009.03300,"MMMLU extends broad academic knowledge testing to multiple languages, covering many subjects and requiring consistent reasoning across linguistic contexts. It probes multilingual comprehension and cross-domain generalization under standardized formats.","Language Comprehension, Semantic Understanding & Context Recognition, Logical Reasoning, Working Memory"
MMMU,https://mmmu-benchmark.github.io/,https://arxiv.org/abs/2311.16502,"MMMU evaluates multimodal expert reasoning across many disciplines by combining images (diagrams, plots, figures) with text questions and multiple-choice answers. It tests whether models can integrate visual evidence with domain knowledge to reach a correct conclusion.","Visual Perception, Scene Understanding & Visual Reasoning, Multisensory Integration, Logical Reasoning, Working Memory, Language Comprehension"
LAB-Bench FigQA,https://huggingface.co/datasets/futurehouse/lab-bench,https://arxiv.org/abs/2407.10362,LAB-Bench FigQA measures whether models can interpret complex scientific figures (especially in biology) and answer questions that require careful visual reading and scientific reasoning. It targets practical figure-grounded inference rather than generic image captioning.,"Scene Understanding & Visual Reasoning, Visual Attention & Eye Movements, Logical Reasoning, Semantic Understanding & Context Recognition, Language Comprehension"
CharXiv Reasoning,https://charxiv.github.io/,https://arxiv.org/abs/2406.18521,"CharXiv Reasoning tests whether a model can answer questions about scientific paper figures and charts, often requiring extracting quantitative/structural information from visuals. It emphasizes figure-grounded reasoning and precise interpretation of plotted or diagrammed evidence.","Scene Understanding & Visual Reasoning, Visual Perception, Logical Reasoning, Working Memory, Language Comprehension"
Video-MMMU,https://videommmu.github.io/,https://arxiv.org/abs/2501.13826,"Video-MMMU extends multimodal understanding to video, requiring models to integrate information across time to answer questions about events, procedures, or visual details. It stresses temporal integration, attention to salient frames, and coherent reasoning from dynamic content.","Visual Perception, Attention, Working Memory, Cognitive Timing & Predictive Modeling, Multisensory Integration"
FACTS Benchmark Suite,https://deepmind.google/blog/facts-benchmark-suite-systematically-evaluating-the-factuality-of-large-language-models/,https://arxiv.org/abs/2512.10791,"FACTS Benchmark Suite systematically evaluates factuality by measuring whether model outputs remain consistent with ground truth or provided sources across varied settings. It focuses on reducing hallucinations, maintaining faithfulness, and resisting unsupported inferences.","Semantic Understanding & Context Recognition, Inhibitory Control, Self-reflection, Working Memory, Language Comprehension"
Global PIQA,https://huggingface.co/datasets/mrlbenchmarks/global-piqa-nonparallel,https://arxiv.org/abs/2510.24081,"Global PIQA evaluates physical commonsense reasoning across many languages and cultures, typically using short scenarios that require selecting the more plausible action or outcome. It probes whether models maintain grounded intuitions about the physical world across linguistic variation.","Language Comprehension, Logical Reasoning, Semantic Understanding & Context Recognition, Spatial Representation & Mapping"
MRCR v2 (8-needle),https://huggingface.co/datasets/openai/mrcr,https://arxiv.org/abs/2409.12640,MRCR v2 (8-needle) tests long-context retrieval and multi-round coreference by embedding multiple similar “needle” interactions within long “haystack” dialogues and asking for the response to a specific needle. It stresses maintaining and retrieving the right referenced information amid interference.,"Working Memory, Attention, Semantic Understanding & Context Recognition, Episodic Memory, Inhibitory Control"
GDPval,https://openai.com/index/gdpval/,https://arxiv.org/abs/2510.04374,"GDPval evaluates well-specified professional knowledge-work tasks spanning many occupations, judged against outputs from industry professionals. It emphasizes producing usable work artifacts and making correct procedural choices under realistic constraints and rubrics.","Planning, Decision-making, Language Production, Semantic Understanding & Context Recognition, Social Reasoning & Theory of Mind, Adaptive Error Correction"
Graphwalks,https://huggingface.co/datasets/openai/graphwalks,,"Graphwalks evaluates algorithmic reasoning over graphs by requiring models to follow traversal or relational queries that demand step-by-step tracking of nodes and edges. It emphasizes precise state tracking and resistance to distraction in long, structured sequences.","Logical Reasoning, Working Memory, Attention, Spatial Representation & Mapping, Inhibitory Control"
Toolathon,https://toolathlon.xyz,https://arxiv.org/abs/2510.25726,"Toolathon evaluates general tool-using ability across diverse APIs and environments, requiring models to select tools, call them correctly, and compose results into a final answer. It stresses robust orchestration, error handling, and task decomposition under a unified harness.","Planning, Decision-making, Adaptive Error Correction, Working Memory, Semantic Understanding & Context Recognition"
FrontierMath,https://epoch.ai/frontiermath,https://arxiv.org/abs/2411.04872,"FrontierMath evaluates expert-level mathematics, including problems intended to be difficult even for strong models and to better reflect research-grade reasoning. It emphasizes long multi-step derivations, careful constraint management, and high precision in intermediate reasoning.","Logical Reasoning, Working Memory, Planning, Cognitive Flexibility, Adaptive Error Correction"
