Benchmark,Website,Paper,Description,Cognitive Functions
SWE-bench Verified,https://openai.com/index/introducing-swe-bench-verified/,https://arxiv.org/abs/2310.06770,"SWE-bench Verified evaluates software-engineering agents on real GitHub issues where the model must produce a patch that makes the project’s tests pass. The Verified subset filters to tasks that have been human-checked as solvable and correctly specified, reducing noise from ambiguous or broken tasks.","Planning, Logical Reasoning, Adaptive Error Correction, Working Memory, Semantic Understanding & Context Recognition, Language Comprehension, Language Production"
SWE-bench Multilingual,https://www.swebench.com/multilingual.html,https://arxiv.org/abs/2504.21798,"SWE-bench Multilingual extends the SWE-bench paradigm beyond Python to multiple programming languages, requiring agents to understand repos, tests, and toolchains across language ecosystems. It stresses cross-language transfer, debugging under unfamiliar conventions, and maintaining correctness under different build and dependency patterns.","Cognitive Flexibility, Planning, Logical Reasoning, Adaptive Error Correction, Working Memory, Semantic Understanding & Context Recognition, Language Comprehension, Language Production"
SWE-bench Pro,https://scale.com/research/swe_bench_pro,https://arxiv.org/abs/2509.16941,"SWE-bench Pro is a larger and harder software-engineering benchmark designed to be more diverse and more resistant to shortcut solutions and contamination, spanning multiple languages and industrially realistic tasks. Models must navigate larger codebases, interpret issue requirements, and iteratively refine patches to satisfy comprehensive test suites.","Planning, Decision-making, Logical Reasoning, Adaptive Error Correction, Working Memory, Semantic Understanding & Context Recognition, Language Comprehension, Language Production"
Terminal-Bench 2.0,https://www.tbench.ai/,,"Terminal-Bench 2.0 evaluates agentic performance in command-line environments where models must execute multi-step workflows using shells, filesystems, and standard developer tools. It emphasizes practical autonomy: choosing commands, inspecting outputs, recovering from errors, and completing goals under execution constraints.","Planning, Decision-making, Adaptive Error Correction, Working Memory, Semantic Understanding & Context Recognition, Language Comprehension, Language Production"
BrowseComp,https://openai.com/index/browsecomp/,https://arxiv.org/abs/2504.12516,"BrowseComp measures deep-research capability by requiring models to locate, synthesize, and justify answers using browsing or retrieval tools over a controlled document collection. It targets end-to-end information-seeking behavior: query formulation, evidence gathering, cross-checking, and final synthesis with citations or grounded rationale.","Planning, Decision-making, Episodic Memory, Working Memory, Semantic Understanding & Context Recognition, Language Comprehension, Language Production, Attention"
τ2-bench,https://sierra.ai/uk/blog/benchmarking-ai-agents,https://arxiv.org/abs/2406.12045,"τ2-bench evaluates interactive agent behavior in customer-support style environments (e.g., retail, airline, telecom) where the model must use APIs and follow domain policies over multi-turn dialogues. It tests whether an agent can balance helpfulness with constraints, maintain state across turns, and avoid policy violations or loopholes.","Social Reasoning & Theory of Mind, Empathy, Inhibitory Control, Planning, Decision-making, Working Memory, Language Comprehension, Language Production, Attention"
OSWorld,https://os-world.github.io/,https://arxiv.org/abs/2404.07972,"OSWorld benchmarks multimodal computer-use agents that operate a desktop-like environment to accomplish tasks across applications via screenshots and UI interaction. Success requires interpreting visual interfaces, sequencing actions over many steps, and correcting course when the UI state diverges from expectations.","Visual Perception, Visual Attention & Eye Movements, Scene Understanding & Visual Reasoning, Sensorimotor Coordination, Planning, Decision-making, Adaptive Error Correction, Working Memory"
ARC-AGI,https://arcprize.org/arc-agi,https://arxiv.org/abs/1911.01547,"ARC-AGI is a fluid-intelligence benchmark of novel grid transformation puzzles where a system must infer the underlying rule from only a few demonstrations and generalize to a new input. It emphasizes systematic generalization, compositional pattern induction, and robustness to unfamiliar tasks rather than memorized knowledge.","Logical Reasoning, Cognitive Flexibility, Working Memory, Spatial Representation & Mapping, Scene Understanding & Visual Reasoning, Visual Perception, Planning"
Vending-Bench 2,https://andonlabs.com/evals/vending-bench-2,https://arxiv.org/abs/2502.15840,"Vending-Bench 2 evaluates long-horizon autonomy in a simulated business setting where an agent manages a vending-machine operation over many decisions (e.g., procurement, pricing, inventory, negotiation). It stresses sustained coherence, strategic planning under uncertainty, and adapting policies based on outcomes over time.","Planning, Decision-making, Reward Mechanisms, Working Memory, Episodic Memory, Adaptive Error Correction, Self-reflection"
MCP-Atlas,https://scale.com/leaderboard/mcp_atlas,,"MCP-Atlas measures real-world tool-use competence via the Model Context Protocol, requiring models to discover available tools, call them with correct schemas, handle errors, and compose multi-step workflows across services. It targets practical orchestration and reliability when interacting with authentic APIs and intermediate results.","Planning, Decision-making, Adaptive Error Correction, Working Memory, Semantic Understanding & Context Recognition, Language Comprehension, Language Production"
FinanceAgent,https://www.vals.ai/benchmarks/finance_agent,,"FinanceAgent assesses agent performance on tasks typical of an entry-level financial analyst, such as analyzing documents, extracting structured facts, building analyses, and producing defensible outputs. It emphasizes applied reasoning under domain constraints, correctness of computations and assumptions, and clear communication of results.","Logical Reasoning, Decision-making, Planning, Working Memory, Semantic Understanding & Context Recognition, Language Comprehension, Language Production"
CyberGym,https://www.cybergym.io/,https://arxiv.org/abs/2506.02548,"CyberGym evaluates cybersecurity agents on realistic vulnerability tasks, including identifying known weakness patterns in real codebases and attempting discovery of previously unknown issues. It stresses careful code comprehension, hypothesis-driven testing, and iterative debugging/exploitation reasoning under strict success criteria.","Logical Reasoning, Planning, Adaptive Error Correction, Working Memory, Semantic Understanding & Context Recognition, Inhibitory Control, Attention"
SpreadsheetBench,https://spreadsheetbench.github.io/,https://arxiv.org/abs/2406.14991,"SpreadsheetBench tests an agent’s ability to navigate and manipulate spreadsheets to solve real-world tasks, often requiring formulas, transformations, and multi-step bookkeeping operations. It emphasizes structured state tracking across cells/sheets, procedural accuracy, and error checking when outputs must match exact targets.","Planning, Decision-making, Working Memory, Adaptive Error Correction, Logical Reasoning, Semantic Understanding & Context Recognition, Attention"
Humanity’s Last Exam,https://agi.safe.ai/,https://arxiv.org/abs/2501.14249,"Humanity’s Last Exam is a difficult, frontier-oriented benchmark spanning many expert domains (and often multimodal inputs) to probe broad reasoning and knowledge under hard, long-form questions. It rewards careful synthesis, multi-step derivations, and grounding answers in the provided context rather than shallow recall.","Language Comprehension, Language Production, Logical Reasoning, Working Memory, Semantic Understanding & Context Recognition, Scene Understanding & Visual Reasoning, Multisensory Integration"
AIME 2025,https://matharena.ai/?view=problem&comp=aime--aime_2025,https://arxiv.org/abs/2505.23281,"AIME 2025 is a set of competition-style mathematics problems that require multi-step derivations and exact numerical answers. It probes algebraic and combinatorial reasoning, precision under symbolic manipulation, and the ability to maintain intermediate state over lengthy solutions.","Logical Reasoning, Working Memory, Planning, Adaptive Error Correction, Attention"
GPQA Diamond,https://artificialanalysis.ai/evaluations/gpqa-diamond,https://arxiv.org/abs/2311.12022,"GPQA Diamond is a high-quality subset of graduate-level science multiple-choice questions designed to be difficult to answer by simple lookup and to require genuine understanding. It emphasizes reasoning over scientific concepts, careful discrimination among plausible distractors, and consistency across physics, chemistry, and biology.","Logical Reasoning, Semantic Understanding & Context Recognition, Working Memory, Language Comprehension, Decision-making"
MMMLU,https://huggingface.co/datasets/openai/MMMLU,https://arxiv.org/abs/2009.03300,"MMMLU extends broad academic QA evaluation across many subjects and multiple non-English languages, stressing multilingual understanding and knowledge transfer. It measures whether models preserve reasoning quality and factual competence when prompts and options vary by language and cultural/linguistic framing.","Language Comprehension, Language Production, Semantic Understanding & Context Recognition, Logical Reasoning, Cognitive Flexibility, Working Memory"
MMMU,https://mmmu-benchmark.github.io/,https://arxiv.org/abs/2311.16502,"MMMU is a multimodal benchmark spanning many disciplines where questions require jointly using text and images (e.g., diagrams, charts, documents) to answer. It targets integrated visual-text reasoning, extracting salient evidence from complex visuals, and maintaining coherent intermediate representations across modalities.","Multisensory Integration, Visual Perception, Scene Understanding & Visual Reasoning, Visual Attention & Eye Movements, Language Comprehension, Language Production, Working Memory, Logical Reasoning"
LAB-Bench FigQA,https://huggingface.co/datasets/futurehouse/lab-bench,https://arxiv.org/abs/2407.10362,"LAB-Bench FigQA evaluates whether models can correctly interpret scientific figures from biology papers, including plots, multi-panel images, and annotated diagrams. It stresses precise visual evidence extraction, mapping visual elements to textual claims, and reasoning about experimental results and relationships depicted in figures.","Visual Perception, Scene Understanding & Visual Reasoning, Multisensory Integration, Attention, Working Memory, Logical Reasoning, Semantic Understanding & Context Recognition"
WebArena,https://webarena.dev/,https://arxiv.org/abs/2307.13854,"WebArena benchmarks autonomous web agents that must complete realistic tasks across multiple web applications by navigating pages, filling forms, and interacting with dynamic interfaces. It emphasizes long-horizon planning, robust state tracking, recovery from mistakes, and effective use of web UI affordances to reach task goals.","Planning, Decision-making, Adaptive Error Correction, Working Memory, Visual Perception, Visual Attention & Eye Movements, Scene Understanding & Visual Reasoning, Sensorimotor Coordination, Attention"
