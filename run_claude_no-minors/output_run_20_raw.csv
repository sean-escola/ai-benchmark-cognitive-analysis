Benchmark,Website,Paper,Description,Cognitive Functions
SWE-bench Verified,https://openai.com/index/introducing-swe-bench-verified/,https://arxiv.org/abs/2310.06770,"SWE-bench Verified evaluates software engineering agents on real GitHub issues by requiring them to generate a patch that makes a project’s tests pass. The “Verified” split consists of tasks confirmed by humans to be solvable and reliably graded, aiming to measure end-to-end bug fixing rather than isolated code writing.","Planning, Decision-making, Logical Reasoning, Adaptive Error Correction, Working Memory, Semantic Understanding & Context Recognition, Language Comprehension (minor), Language Production (minor)"
SWE-bench Multilingual,https://www.swebench.com/multilingual.html,https://arxiv.org/abs/2504.21798,"SWE-bench Multilingual extends SWE-bench-style repository patching to multiple programming languages, testing whether agents can localize and fix bugs beyond Python ecosystems. It probes cross-language generalization in understanding codebases, toolchains, and tests under realistic repo constraints.","Language Comprehension, Semantic Understanding & Context Recognition, Logical Reasoning, Cognitive Flexibility, Planning, Decision-making, Adaptive Error Correction, Working Memory (minor)"
SWE-bench Pro,https://scale.com/research/swe_bench_pro,https://arxiv.org/abs/2509.16941,"SWE-bench Pro is a larger, more challenging software engineering benchmark emphasizing industrially relevant tasks and stronger contamination resistance, typically spanning multiple languages and more complex repos. It focuses on sustained, end-to-end engineering competence: diagnosing issues, implementing fixes, and satisfying automated checks.","Planning, Decision-making, Logical Reasoning, Adaptive Error Correction, Working Memory, Semantic Understanding & Context Recognition, Cognitive Flexibility (minor), Language Production (minor)"
Terminal-Bench 2.0,https://www.tbench.ai/,,"Terminal-Bench 2.0 measures agent performance on real command-line tasks inside sandboxed environments, such as debugging, building, and manipulating files and processes. Success depends on selecting correct shell commands, interpreting outputs, and iteratively recovering from errors under resource constraints.","Planning, Decision-making, Adaptive Error Correction, Working Memory, Logical Reasoning, Attention (minor), Language Comprehension (minor)"
BrowseComp,https://openai.com/index/browsecomp/,https://arxiv.org/abs/2504.12516,"BrowseComp evaluates “browse-and-answer” capability on information-seeking questions that require searching, gathering evidence, and synthesizing an answer from multiple sources (often with a controlled corpus or reproducible setup). It stresses research-style decomposition, retrieval strategy, and attribution-grounded synthesis rather than pure recall.","Planning, Attention, Semantic Understanding & Context Recognition, Working Memory, Logical Reasoning, Episodic Memory (minor), Self-reflection (minor), Language Production (minor)"
τ2-bench,https://sierra.ai/uk/blog/benchmarking-ai-agents,https://arxiv.org/abs/2406.12045,"τ2-bench evaluates interactive customer-support agents that must follow domain policies while using APIs/tools across multi-turn dialogues (e.g., retail, airline, telecom). The benchmark emphasizes robust instruction/policy adherence, state tracking across turns, and choosing compliant action sequences under user pressure.","Inhibitory Control, Decision-making, Planning, Working Memory, Social Reasoning & Theory of Mind, Language Comprehension, Language Production, Empathy (minor)"
OSWorld,https://os-world.github.io/,https://arxiv.org/abs/2404.07972,"OSWorld is a multimodal computer-use benchmark where agents interact with a desktop OS to complete tasks (navigation, settings changes, file operations, web/app workflows) via screenshots and actions. It tests perception-to-action coupling, multi-step planning, and robustness to UI variability and intermediate failures.","Visual Perception, Scene Understanding & Visual Reasoning, Visual Attention & Eye Movements, Sensorimotor Coordination, Planning, Decision-making, Adaptive Error Correction (minor), Working Memory (minor)"
ARC-AGI,https://arcprize.org/arc-agi,https://arxiv.org/abs/1911.01547,ARC-AGI tests few-shot abstract reasoning over grid-based puzzles: models infer latent transformation rules from a handful of input–output examples and must generalize to a new input. It is designed to emphasize fluid reasoning and compositional generalization with minimal training signal from the task itself.,"Logical Reasoning, Cognitive Flexibility, Spatial Representation & Mapping, Visual Perception, Working Memory, Planning (minor), Cognitive Timing & Predictive Modeling (minor)"
Vending-Bench 2,https://andonlabs.com/evals/vending-bench-2,https://arxiv.org/abs/2502.15840,"Vending-Bench 2 evaluates long-horizon agent coherence and strategy by simulating management of a vending-machine business over an extended period with many sequential decisions. High scores require sustained goal pursuit (inventory, pricing, supplier negotiation), adaptation to changing conditions, and error recovery without drifting off-task.","Planning, Decision-making, Reward Mechanisms, Working Memory, Episodic Memory (minor), Adaptive Error Correction (minor), Motivational Drives (minor), Language Production (minor)"
MCP-Atlas,https://scale.com/leaderboard/mcp_atlas,,"MCP-Atlas measures real-world tool-use competence via the Model Context Protocol (MCP), requiring models to discover and correctly invoke tools across multi-step workflows and synthesize results. Tasks stress correct API selection/argumenting, handling tool errors, and coordinating information across calls in production-like settings.","Planning, Decision-making, Semantic Understanding & Context Recognition, Adaptive Error Correction, Working Memory, Language Comprehension (minor), Language Production (minor)"
FinanceAgent,https://www.vals.ai/benchmarks/finance_agent,,"FinanceAgent evaluates performance on tasks representative of an entry-level financial analyst, such as extracting information from documents, performing calculations, and producing justified outputs. It emphasizes structured analysis, numerical reasoning, and assembling decision-ready summaries from heterogeneous financial inputs.","Logical Reasoning, Semantic Understanding & Context Recognition, Working Memory, Planning, Decision-making, Language Production (minor)"
CyberGym,https://www.cybergym.io/,https://arxiv.org/abs/2506.02548,"CyberGym evaluates cybersecurity agent capability on large-scale, real-software vulnerability tasks, including identifying known vulnerability instances and, in some settings, finding new ones. It stresses code comprehension, adversarial/defensive reasoning, and iterative hypothesis testing under realistic constraints.","Logical Reasoning, Planning, Decision-making, Adaptive Error Correction, Semantic Understanding & Context Recognition, Working Memory (minor), Inhibitory Control (minor)"
SpreadsheetBench,https://spreadsheetbench.github.io/,https://arxiv.org/abs/2406.14991,"SpreadsheetBench measures an agent’s ability to navigate and manipulate complex spreadsheets to solve real-world inspired problems, often requiring edits, formulas, and multi-step transformations. It tests whether models can maintain state across many cell-level operations while keeping outputs consistent with constraints.","Planning, Working Memory, Decision-making, Logical Reasoning, Adaptive Error Correction (minor), Visual Perception (minor), Sensorimotor Coordination (minor)"
Humanity’s Last Exam,https://agi.safe.ai/,https://arxiv.org/abs/2501.14249,"Humanity’s Last Exam is a frontier, multimodal benchmark spanning difficult questions across many expert domains, designed to stress deep reasoning and knowledge integration. It often requires combining textual evidence, diagrams/figures, and careful multi-step inference rather than short factual recall.","Language Comprehension, Logical Reasoning, Semantic Understanding & Context Recognition, Working Memory, Multisensory Integration, Scene Understanding & Visual Reasoning (minor), Language Production (minor)"
AIME 2025,https://matharena.ai/?view=problem&comp=aime--aime_2025,https://arxiv.org/abs/2505.23281,"AIME 2025 consists of competition mathematics problems that typically require multi-step derivations, careful constraint handling, and exact answers. It is used to assess structured mathematical reasoning and reliability under nontrivial problem-solving depth.","Logical Reasoning, Working Memory, Planning, Decision-making (minor), Cognitive Timing & Predictive Modeling (minor)"
GPQA Diamond,https://artificialanalysis.ai/evaluations/gpqa-diamond,https://arxiv.org/abs/2311.12022,"GPQA Diamond is a challenging multiple-choice science benchmark curated to be “Google-proof,” with questions that require expert-level reasoning in biology, chemistry, and physics. The Diamond subset emphasizes high-quality items where experts succeed and non-experts often fail, targeting deep scientific understanding over surface cues.","Language Comprehension, Logical Reasoning, Semantic Understanding & Context Recognition, Working Memory (minor), Decision-making (minor)"
MMMLU,https://huggingface.co/datasets/openai/MMMLU,https://arxiv.org/abs/2009.03300,"MMMLU extends MMLU-style breadth testing across many subjects into multiple languages, probing both knowledge and reasoning under multilingual variation. It assesses whether models preserve competence across linguistic contexts and domain shifts without heavy task-specific prompting.","Language Comprehension, Semantic Understanding & Context Recognition, Logical Reasoning, Cognitive Flexibility, Working Memory (minor), Language Production (minor)"
MMMU,https://mmmu-benchmark.github.io/,https://arxiv.org/abs/2311.16502,"MMMU is a multimodal, multi-discipline benchmark requiring models to answer expert-level questions grounded in images (charts, diagrams, tables, scenes) plus text. It targets cross-modal reasoning: extracting visual information, aligning it with textual context, and performing multi-step inference.","Visual Perception, Scene Understanding & Visual Reasoning, Multisensory Integration, Language Comprehension, Logical Reasoning, Visual Attention & Eye Movements (minor), Working Memory (minor)"
LAB-Bench FigQA,https://huggingface.co/datasets/futurehouse/lab-bench,https://arxiv.org/abs/2407.10362,"LAB-Bench FigQA evaluates whether models can correctly interpret complex scientific figures from biology papers and answer questions that depend on precise visual reading and domain context. It is designed to reflect realistic scientific analysis where key evidence is embedded in plots, schematics, and multi-panel figures.","Scene Understanding & Visual Reasoning, Visual Perception, Multisensory Integration, Semantic Understanding & Context Recognition, Logical Reasoning, Visual Attention & Eye Movements (minor), Working Memory (minor)"
WebArena,https://webarena.dev/,https://arxiv.org/abs/2307.13854,"WebArena evaluates autonomous web agents performing realistic tasks across multiple web apps (e-commerce, CMS, forums, code hosting, maps), requiring navigation and interaction with dynamic pages. It stresses long-horizon planning, state tracking, and robust execution despite UI noise, partial observability, and action failures.","Planning, Decision-making, Working Memory, Attention, Visual Perception, Sensorimotor Coordination, Adaptive Error Correction, Inhibitory Control (minor)"
