Benchmark,Website,Paper,Description,Cognitive Functions
SWE-bench Pro,https://scale.com/research/swe_bench_pro,https://arxiv.org/abs/2509.16941,"SWE-bench Pro is a large-scale software engineering benchmark where a model must modify real repositories to resolve issues, producing a patch that passes the project’s tests and task-specific checks. Compared with earlier SWE-bench variants, it emphasizes harder, more realistic and contamination-resistant tasks across multiple languages and codebases, stressing end-to-end debugging and implementation.","Language Comprehension, Language Production, Logical Reasoning, Planning, Working Memory, Adaptive Error Correction"
OSWorld,https://os-world.github.io/,https://arxiv.org/abs/2404.07972,"OSWorld evaluates computer-use agents on completing real tasks in a full desktop operating system environment (e.g., using apps, settings, files, and browsers) under step and time constraints. It tests whether models can perceive GUI state, plan multi-step actions, recover from mistakes, and robustly interact with dynamic interfaces.","Visual Perception, Scene Understanding & Visual Reasoning, Visual Attention & Eye Movements, Planning, Decision-making, Sensorimotor Coordination, Working Memory, Adaptive Error Correction"
ARC-AGI,https://arcprize.org/arc-agi,https://arxiv.org/abs/1911.01547,"ARC-AGI is a fluid intelligence benchmark where models infer latent rules from a few input–output grid examples and produce the correct output grid for a new input. It is designed to minimize reliance on memorized knowledge and instead measure abstraction, rule induction, and generalization to novel tasks.","Logical Reasoning, Cognitive Flexibility, Working Memory, Attention, Spatial Representation & Mapping, Scene Understanding & Visual Reasoning"
Vending-Bench 2,https://andonlabs.com/evals/vending-bench-2,https://arxiv.org/abs/2502.15840,"Vending-Bench 2 measures long-horizon agent coherence and strategy by having a model run a simulated vending-machine business over extended time, making thousands of decisions (inventory, pricing, supplier negotiation, budgeting). High scores require sustained planning, adaptation to changing conditions, and consistent execution of business workflows without drifting goals or state.","Planning, Decision-making, Working Memory, Reward Mechanisms, Semantic Understanding & Context Recognition, Adaptive Error Correction, Cognitive Timing & Predictive Modeling"
MCP-Atlas,https://scale.com/leaderboard/mcp_atlas,,"MCP-Atlas evaluates real-world tool use through the Model Context Protocol (MCP), where models must discover tools, call them with correct arguments, and compose multi-step workflows across services. It stresses robust API interaction, error handling, and synthesis of tool outputs into correct final answers.","Language Comprehension, Planning, Decision-making, Working Memory, Adaptive Error Correction, Semantic Understanding & Context Recognition"
CyberGym,https://www.cybergym.io/,https://arxiv.org/abs/2506.02548,"CyberGym evaluates agents on cybersecurity tasks including finding known vulnerabilities in real open-source projects from high-level weakness descriptions and, in some settings, discovering previously unknown issues. It emphasizes repository navigation, exploit/bug reasoning, and iterative debugging of hypotheses under realistic constraints.","Logical Reasoning, Planning, Adaptive Error Correction, Working Memory, Language Comprehension, Decision-making, Attention"
Humanity’s Last Exam,https://agi.safe.ai/,https://arxiv.org/abs/2501.14249,"Humanity’s Last Exam (HLE) is a challenging benchmark intended to probe frontier-level academic and professional reasoning, often spanning multiple disciplines and modalities. Questions are designed to be difficult to answer via shallow pattern matching, requiring careful interpretation, multi-step reasoning, and (in some evaluation setups) effective tool use.","Language Comprehension, Language Production, Logical Reasoning, Working Memory, Semantic Understanding & Context Recognition, Multisensory Integration, Scene Understanding & Visual Reasoning"
GPQA Diamond,https://artificialanalysis.ai/evaluations/gpqa-diamond,https://arxiv.org/abs/2311.12022,"GPQA Diamond is a high-quality subset of graduate-level, “Google-proof” multiple-choice science questions where non-experts tend to fail but domain experts succeed. It targets deep scientific understanding and reasoning rather than retrieval of common facts.","Language Comprehension, Logical Reasoning, Semantic Understanding & Context Recognition, Working Memory, Attention"
MMMU-Pro,https://mmmu-benchmark.github.io/,https://arxiv.org/abs/2409.02813,"MMMU-Pro is a difficult multimodal benchmark spanning many disciplines, where models answer questions requiring joint understanding of images (e.g., diagrams, charts, figures) and text. It focuses on expert-level visual reasoning, quantitative interpretation, and multi-step inference over multimodal evidence.","Visual Perception, Scene Understanding & Visual Reasoning, Multisensory Integration, Language Comprehension, Logical Reasoning, Spatial Representation & Mapping, Working Memory, Attention"
OmniDocBench 1.5,https://github.com/opendatalab/OmniDocBench,https://arxiv.org/abs/2412.07626,"OmniDocBench 1.5 evaluates document understanding and OCR-centric capabilities over complex layouts that can include text, tables, formulas, and reading order. It stresses faithful extraction and structured interpretation of visually-presented information, including layout-sensitive reconstruction.","Visual Perception, Scene Understanding & Visual Reasoning, Visual Attention & Eye Movements, Language Comprehension, Working Memory, Attention, Spatial Representation & Mapping"
Video-MMMU,https://videommmu.github.io/,https://arxiv.org/abs/2501.13826,"Video-MMMU extends multimodal understanding to video, requiring models to answer questions grounded in sequences of frames and temporal events. It tests whether a model can integrate visual evidence over time, track state changes, and reason about actions and causality in dynamic scenes.","Visual Perception, Scene Understanding & Visual Reasoning, Multisensory Integration, Cognitive Timing & Predictive Modeling, Working Memory, Attention, Logical Reasoning"
LiveCodeBench Pro,https://livecodebenchpro.com/projects/livecodebench-pro/leaderboard,https://arxiv.org/abs/2506.11928,"LiveCodeBench Pro is a competitive coding benchmark that evaluates a model’s ability to solve programming problems under realistic constraints, typically emphasizing correctness, robustness, and timeliness. It targets not just writing code, but also iterative debugging and aligning implementations with precise specifications.","Language Comprehension, Language Production, Logical Reasoning, Planning, Working Memory, Adaptive Error Correction, Attention"
FACTS Benchmark Suite,https://deepmind.google/blog/facts-benchmark-suite-systematically-evaluating-the-factuality-of-large-language-models/,https://arxiv.org/abs/2512.10791,"FACTS Benchmark Suite systematically evaluates factuality and grounding behavior across diverse factuality-related tasks, aiming to separate genuine knowledge/grounding from plausible-sounding hallucinations. It emphasizes accuracy under ambiguity, correct attribution/grounding when evidence is available, and restraint when evidence is insufficient.","Semantic Understanding & Context Recognition, Language Comprehension, Language Production, Inhibitory Control, Self-reflection, Working Memory, Logical Reasoning"
Global PIQA,https://huggingface.co/datasets/mrlbenchmarks/global-piqa-nonparallel,https://arxiv.org/abs/2510.24081,"Global PIQA evaluates practical physical commonsense reasoning across many languages and cultural contexts, focusing on whether models choose actions or explanations consistent with everyday physics and affordances. It is designed to test generalization of physical reasoning beyond English-centric distributions.","Language Comprehension, Semantic Understanding & Context Recognition, Logical Reasoning, Spatial Representation & Mapping, Scene Understanding & Visual Reasoning"
MRCR v2 (8-needle),https://huggingface.co/datasets/openai/mrcr,https://arxiv.org/abs/2409.12640,"MRCR v2 is a long-context evaluation where multiple similar “needle” requests/responses are embedded within a large “haystack,” and the model must retrieve and reproduce the response associated with a specified needle. The 8-needle variant increases interference, testing robust retrieval, disambiguation, and context tracking at long lengths.","Working Memory, Attention, Episodic Memory, Semantic Understanding & Context Recognition, Inhibitory Control"
GDPval,https://openai.com/index/gdpval/,https://arxiv.org/abs/2510.04374,"GDPval measures performance on well-specified professional knowledge-work tasks spanning many occupations, judged by expert human evaluators via head-to-head comparisons. Tasks often require producing realistic work artifacts (e.g., plans, analyses, spreadsheets/presentations) and making decisions that satisfy constraints and stakeholder needs.","Planning, Decision-making, Language Production, Language Comprehension, Social Reasoning & Theory of Mind, Working Memory, Semantic Understanding & Context Recognition, Self-reflection"
SWE-Lancer,https://openai.com/index/swe-lancer/,https://arxiv.org/abs/2502.12115,"SWE-Lancer evaluates software engineering agents on scoped, real-world engineering tasks that more closely resemble contracted feature work or bugfix “tickets,” often requiring multi-file changes and integration awareness. It emphasizes end-to-end task completion quality, including reasoning about codebase structure and producing correct patches.","Language Comprehension, Language Production, Planning, Decision-making, Working Memory, Logical Reasoning, Adaptive Error Correction"
FrontierMath,https://epoch.ai/frontiermath,https://arxiv.org/abs/2411.04872,"FrontierMath is an expert-level mathematics benchmark intended to measure advanced mathematical problem solving beyond routine competition questions, often requiring deep multi-step derivations. It targets rigorous reasoning, careful handling of definitions/constraints, and sustained problem solving over long solution chains.","Logical Reasoning, Planning, Working Memory, Cognitive Flexibility, Adaptive Error Correction, Attention"
