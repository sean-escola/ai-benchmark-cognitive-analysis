Benchmark,Website,Paper,Description,Cognitive Functions
SWE-bench Pro,https://scale.com/research/swe_bench_pro,https://arxiv.org/abs/2509.16941,"SWE-bench Pro is a large-scale software engineering benchmark where a model is given a real code repository plus an issue description and must generate a patch that fixes the problem. It emphasizes realistic debugging and code changes that pass tests across multiple projects and (in the Pro variant) multiple programming languages, with an emphasis on higher difficulty and contamination resistance.","Language Comprehension, Language Production, Logical Reasoning, Planning, Working Memory, Adaptive Error Correction"
OSWorld,https://os-world.github.io/,https://arxiv.org/abs/2404.07972,"OSWorld evaluates multimodal “computer use” agents on completing tasks inside a real operating-system desktop environment by interacting with GUIs (e.g., clicking, typing, navigating apps). Success requires perceiving screen state, choosing multi-step actions, and recovering from errors under step and time constraints.","Visual Perception, Visual Attention & Eye Movements, Attention, Planning, Decision-making, Sensorimotor Coordination, Working Memory, Adaptive Error Correction"
ARC-AGI,https://arcprize.org/arc-agi,https://arxiv.org/abs/1911.01547,"ARC-AGI measures fluid, novel pattern reasoning using small grid-based input–output examples where the rule must be inferred from only a few demonstrations. It is designed to emphasize generalization to new abstract transformations rather than memorized domain knowledge.","Logical Reasoning, Working Memory, Cognitive Flexibility, Planning, Spatial Representation & Mapping, Scene Understanding & Visual Reasoning, Attention"
Vending-Bench 2,https://andonlabs.com/evals/vending-bench-2,https://arxiv.org/abs/2502.15840,"Vending-Bench 2 evaluates long-horizon agent coherence and strategy in a simulated vending-machine business run over many steps (e.g., pricing, inventory, supplier negotiation, responding to events). The metric is typically profit/final balance, rewarding sustained planning, adaptation, and consistent execution across time.","Planning, Decision-making, Reward Mechanisms, Working Memory, Episodic Memory, Cognitive Flexibility, Adaptive Error Correction, Language Comprehension, Language Production"
MCP-Atlas,https://scale.com/leaderboard/mcp_atlas,,"MCP-Atlas measures real-world tool use through the Model Context Protocol (MCP), where models must discover tools, invoke them correctly, and chain multi-step workflows across services. Tasks stress reliable API interaction, argument formation, error handling, and synthesis of tool outputs into a final response.","Planning, Decision-making, Working Memory, Adaptive Error Correction, Language Comprehension, Language Production, Semantic Understanding & Context Recognition"
CyberGym,https://www.cybergym.io/,https://arxiv.org/abs/2506.02548,"CyberGym evaluates cybersecurity agent capabilities on tasks that include identifying known vulnerabilities from descriptions and discovering new vulnerabilities in real open-source codebases. It probes an agent’s ability to reason about program behavior, execute investigative steps, and produce correct exploit-relevant findings or patches under constraints.","Logical Reasoning, Planning, Decision-making, Working Memory, Adaptive Error Correction, Language Comprehension, Language Production"
Humanity’s Last Exam,https://agi.safe.ai/,https://arxiv.org/abs/2501.14249,"Humanity’s Last Exam (HLE) is a broad, frontier-oriented benchmark spanning advanced academic and professional questions, often including multimodal items. It aims to measure integrated reasoning and knowledge under challenging, long-form question styles, sometimes in tool-assisted settings depending on the evaluation protocol.","Language Comprehension, Language Production, Logical Reasoning, Working Memory, Semantic Understanding & Context Recognition, Scene Understanding & Visual Reasoning, Visual Perception"
GPQA Diamond,https://artificialanalysis.ai/evaluations/gpqa-diamond,https://arxiv.org/abs/2311.12022,"GPQA Diamond is a curated subset of very difficult multiple-choice science questions intended to be “Google-proof,” emphasizing reasoning rather than straightforward lookup. The Diamond split focuses on the highest-quality items where experts reliably answer correctly while non-experts often fail.","Language Comprehension, Logical Reasoning, Working Memory, Semantic Understanding & Context Recognition, Decision-making"
MMMU-Pro,https://mmmu-benchmark.github.io/,https://arxiv.org/abs/2409.02813,"MMMU-Pro is a challenging multimodal understanding and reasoning benchmark across many disciplines, where problems require combining text with images such as diagrams, charts, and scientific figures. The Pro variant is designed to be harder and more diagnostic of expert-level multimodal reasoning than earlier MMMU settings.","Visual Perception, Scene Understanding & Visual Reasoning, Multisensory Integration, Language Comprehension, Logical Reasoning, Working Memory, Attention"
OmniDocBench 1.5,https://github.com/opendatalab/OmniDocBench,https://arxiv.org/abs/2412.07626,"OmniDocBench 1.5 evaluates document understanding/OCR systems on complex documents that include mixed text, tables, formulas, and layout/reading-order structure. It tests whether models can faithfully extract and structure information from visually rich documents rather than only recognizing plain text.","Visual Perception, Visual Attention & Eye Movements, Scene Understanding & Visual Reasoning, Language Comprehension, Language Production, Attention, Working Memory, Spatial Representation & Mapping"
Video-MMMU,https://videommmu.github.io/,https://arxiv.org/abs/2501.13826,"Video-MMMU evaluates multimodal reasoning over videos paired with text questions, requiring understanding of events, temporal dependencies, and visual details across frames. It targets robust video understanding beyond static images, including multi-step inference grounded in what occurs over time.","Visual Perception, Visual Attention & Eye Movements, Scene Understanding & Visual Reasoning, Multisensory Integration, Working Memory, Cognitive Timing & Predictive Modeling, Attention, Language Comprehension, Logical Reasoning"
LiveCodeBench Pro,https://livecodebenchpro.com/projects/livecodebench-pro/leaderboard,https://arxiv.org/abs/2506.11928,"LiveCodeBench Pro benchmarks coding ability on recently created programming tasks with executable tests, aiming to reduce contamination and better reflect contemporary developer work. It emphasizes producing correct, runnable code under realistic constraints and is often reported via pass rates or an Elo-style score.","Language Comprehension, Language Production, Logical Reasoning, Planning, Working Memory, Adaptive Error Correction"
FACTS Benchmark Suite,https://deepmind.google/blog/facts-benchmark-suite-systematically-evaluating-the-factuality-of-large-language-models/,https://arxiv.org/abs/2512.10791,"The FACTS Benchmark Suite evaluates factuality-related behaviors such as making supported claims, resisting hallucination, and maintaining consistency under prompts that can induce errors. It aggregates multiple factuality tests to provide a more systematic view of truthfulness and grounding than a single QA metric.","Language Comprehension, Language Production, Inhibitory Control, Semantic Understanding & Context Recognition, Working Memory, Logical Reasoning, Attention, Self-reflection"
Global PIQA,https://huggingface.co/datasets/mrlbenchmarks/global-piqa-nonparallel,https://arxiv.org/abs/2510.24081,"Global PIQA evaluates physical commonsense reasoning across many languages, focusing on whether models can select plausible actions/solutions in everyday scenarios without relying on English-only cues. The non-parallel multilingual design aims to measure robust commonsense generalization across linguistic and cultural contexts.","Language Comprehension, Logical Reasoning, Semantic Understanding & Context Recognition, Decision-making, Working Memory"
MRCR v2 (8-needle),https://huggingface.co/datasets/openai/mrcr,https://arxiv.org/abs/2409.12640,"MRCR v2 (8-needle) is a long-context retrieval and multi-round coreference test where multiple similar “needle” interactions are embedded in a long “haystack,” and the model must reproduce the correct referenced content. The 8-needle setting stresses maintaining and selecting the right context among many confusable candidates.","Working Memory, Episodic Memory, Attention, Semantic Understanding & Context Recognition, Inhibitory Control, Logical Reasoning"
GDPval,https://openai.com/index/gdpval/,https://arxiv.org/abs/2510.04374,"GDPval evaluates well-specified professional knowledge work across many occupations by having models produce real deliverables (e.g., spreadsheets, slide decks, plans) and comparing them against expert human work via judging. It is intended to measure economically relevant end-to-end task performance rather than isolated QA.","Planning, Decision-making, Language Comprehension, Language Production, Working Memory, Semantic Understanding & Context Recognition, Adaptive Error Correction, Self-reflection"
SWE-Lancer,https://openai.com/index/swe-lancer/,https://arxiv.org/abs/2502.12115,"SWE-Lancer evaluates software engineering agents on longer, more open-ended tasks that resemble real developer workflows, often requiring navigating large codebases, making multi-file changes, and validating results. It stresses end-to-end execution quality, including choosing what to change, implementing it correctly, and iterating when tests or checks fail.","Planning, Decision-making, Logical Reasoning, Working Memory, Adaptive Error Correction, Language Comprehension, Language Production"
FrontierMath,https://epoch.ai/frontiermath,https://arxiv.org/abs/2411.04872,"FrontierMath is an advanced mathematics benchmark targeting difficult, research-adjacent problems with careful curation to reduce memorization and emphasize genuine reasoning. It is often analyzed by tiers of difficulty and may be run with or without computational tools, highlighting the boundary between symbolic reasoning and computation-assisted solving.","Logical Reasoning, Working Memory, Planning, Adaptive Error Correction, Cognitive Flexibility, Semantic Understanding & Context Recognition"
