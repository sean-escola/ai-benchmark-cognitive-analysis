Benchmark,Website,Paper,Description,Cognitive Functions,Max AI Tier
SWE-bench Pro,https://scale.com/research/swe_bench_pro,https://arxiv.org/abs/2509.16941,"SWE-bench Pro evaluates software engineering agents on realistic GitHub issues that require producing correct patches in real repositories, with a focus on harder and more contamination-resistant tasks than SWE-bench Verified. Systems must interpret problem statements, navigate codebases, implement fixes, and satisfy automated tests in an end-to-end workflow.","L1: Language Comprehension, Language Production
L2: Planning, Decision-making, Working Memory, Logical Reasoning, Adaptive Error Correction
L3: ",L2
OSWorld,https://os-world.github.io/,https://arxiv.org/abs/2404.07972,"OSWorld evaluates multimodal “computer use” agents that must operate a desktop-like operating system to complete tasks across applications and web pages. Success typically requires visually understanding UI state, planning multi-step procedures, and reliably executing actions while recovering from mistakes.","L1: Visual Perception
L2: Scene Understanding & Visual Reasoning, Visual Attention & Eye Movements, Attention, Planning, Decision-making, Working Memory, Sensorimotor Coordination, Adaptive Error Correction
L3: Inhibitory Control",L3
ARC-AGI,https://arcprize.org/arc-agi,https://arxiv.org/abs/1911.01547,"ARC-AGI measures fluid, example-efficient reasoning on novel grid-based pattern transformation tasks, where models infer the hidden rule from only a few demonstrations. It emphasizes abstraction and generalization rather than memorized domain knowledge, with solutions requiring robust rule induction under distribution shift.","L1: Visual Perception
L2: Logical Reasoning, Working Memory, Spatial Representation & Mapping, Planning
L3: Cognitive Flexibility",L3
Vending-Bench 2,https://andonlabs.com/evals/vending-bench-2,https://arxiv.org/abs/2502.15840,"Vending-Bench 2 tests long-horizon agent coherence by simulating operation of a vending-machine business over an extended period, where the agent manages inventory, pricing, suppliers, and finances. High scores require sustained strategy, adaptation to changing conditions, and consistent decision-making over many sequential steps.","L1: Language Comprehension, Language Production
L2: Planning, Decision-making, Reward Mechanisms, Working Memory, Episodic Memory, Adaptive Error Correction
L3: Cognitive Timing & Predictive Modeling, Self-reflection",L3
MCP-Atlas,https://scale.com/leaderboard/mcp_atlas,,"MCP-Atlas evaluates real-world tool use via the Model Context Protocol (MCP), focusing on selecting, calling, and chaining tools to solve multi-step tasks across heterogeneous services. It stresses correct API invocation, error handling, and synthesizing tool outputs into accurate final responses.","L1: Language Comprehension, Language Production
L2: Planning, Decision-making, Working Memory, Adaptive Error Correction, Semantic Understanding & Context Recognition
L3: ",L2
CyberGym,https://www.cybergym.io/,https://arxiv.org/abs/2506.02548,"CyberGym evaluates cybersecurity capability on large-scale tasks involving identifying known vulnerabilities and discovering previously unknown issues in open-source projects. It requires understanding vulnerability descriptions, reasoning about code and behavior, and iteratively testing hypotheses to reach a correct finding or exploit-relevant diagnosis.","L1: 
L2: Logical Reasoning, Planning, Working Memory, Adaptive Error Correction, Semantic Understanding & Context Recognition
L3: Inhibitory Control",L3
Humanity’s Last Exam,https://agi.safe.ai/,https://arxiv.org/abs/2501.14249,Humanity’s Last Exam is a multimodal benchmark intended to probe frontier-level academic knowledge and reasoning across many disciplines with challenging questions. It tests whether models can integrate domain knowledge with multi-step inference (often including interpreting diagrams/figures) under exam-like constraints.,"L1: Language Comprehension, Visual Perception
L2: Logical Reasoning, Semantic Understanding & Context Recognition, Working Memory, Scene Understanding & Visual Reasoning, Multisensory Integration
L3: ",L2
GPQA Diamond,https://artificialanalysis.ai/evaluations/gpqa-diamond,https://arxiv.org/abs/2311.12022,"GPQA Diamond is a high-quality subset of GPQA consisting of difficult, graduate-level multiple-choice questions in biology, chemistry, and physics designed to be “Google-proof.” It emphasizes deep scientific reasoning and careful discrimination among plausible distractor options rather than shallow recall.","L1: Language Comprehension
L2: Logical Reasoning, Semantic Understanding & Context Recognition, Working Memory
L3: ",L2
MMMU-Pro,https://mmmu-benchmark.github.io/,https://arxiv.org/abs/2409.02813,"MMMU-Pro is an expert-level multimodal benchmark spanning many disciplines, where models answer questions grounded in images (e.g., charts, diagrams, scientific figures) plus text. It measures multimodal understanding and reasoning, often requiring spatial/visual inference combined with domain knowledge.","L1: Visual Perception, Language Comprehension
L2: Scene Understanding & Visual Reasoning, Multisensory Integration, Visual Attention & Eye Movements, Logical Reasoning, Working Memory, Semantic Understanding & Context Recognition
L3: ",L2
OmniDocBench 1.5,https://github.com/opendatalab/OmniDocBench,https://arxiv.org/abs/2412.07626,"OmniDocBench 1.5 evaluates document understanding/OCR by requiring extraction and structured reconstruction of content from complex documents, including text, tables, formulas, and reading order. It stresses robust visual parsing, layout understanding, and faithful transcription into the requested representation.","L1: Visual Perception, Language Comprehension
L2: Visual Attention & Eye Movements, Scene Understanding & Visual Reasoning, Working Memory, Spatial Representation & Mapping
L3: ",L2
Video-MMMU,https://videommmu.github.io/,https://arxiv.org/abs/2501.13826,"Video-MMMU extends multimodal reasoning to the video domain, where models must answer questions that depend on temporally unfolding visual information and accompanying text. It probes understanding of events, temporal causality, and the ability to integrate observations across multiple frames/clips.","L1: Visual Perception
L2: Scene Understanding & Visual Reasoning, Working Memory, Attention, Multisensory Integration, Semantic Understanding & Context Recognition
L3: Cognitive Timing & Predictive Modeling",L3
LiveCodeBench Pro,https://livecodebenchpro.com/projects/livecodebench-pro/leaderboard,https://arxiv.org/abs/2506.11928,"LiveCodeBench Pro evaluates coding performance on fresh, continuously updated programming problems, aiming to reduce contamination and better reflect current developer tasks. It typically rewards not just producing correct code, but also iterative debugging, adapting to constraints, and maintaining correctness across tests.","L1: Language Comprehension, Language Production
L2: Logical Reasoning, Planning, Working Memory, Adaptive Error Correction
L3: ",L2
FACTS Benchmark Suite,https://deepmind.google/blog/facts-benchmark-suite-systematically-evaluating-the-factuality-of-large-language-models/,https://arxiv.org/abs/2512.10791,"The FACTS Benchmark Suite systematically evaluates factuality by measuring how often models produce correct, supported claims across multiple factuality-focused subtests. It targets robustness against hallucination, calibration, and adherence to evidence when generating answers or summaries.","L1: Language Comprehension, Language Production
L2: Semantic Understanding & Context Recognition, Working Memory
L3: Inhibitory Control, Self-reflection",L3
Global PIQA,https://huggingface.co/datasets/mrlbenchmarks/global-piqa-nonparallel,https://arxiv.org/abs/2510.24081,"Global PIQA measures pragmatic and commonsense question answering across languages and cultural contexts, emphasizing what is implied or appropriate in everyday situations. It tests whether models can apply context-sensitive reasoning rather than relying on narrow, culture-bound patterns.","L1: Language Comprehension
L2: Semantic Understanding & Context Recognition, Logical Reasoning, Working Memory
L3: Social Reasoning & Theory of Mind",L3
MRCR v2 (8-needle),https://huggingface.co/datasets/openai/mrcr,https://arxiv.org/abs/2409.12640,"MRCR v2 (8-needle) tests long-context multi-round co-reference/retrieval by inserting multiple similar “needle” requests into long “haystacks” and asking the model to reproduce the response corresponding to a specified needle. It probes precise retrieval under interference, requiring robust tracking of entities and dialogue state across long documents.","L1: Language Comprehension
L2: Working Memory, Attention, Episodic Memory, Semantic Understanding & Context Recognition
L3: ",L2
GDPval,https://openai.com/index/gdpval/,https://arxiv.org/abs/2510.04374,"GDPval evaluates economically meaningful, well-specified professional tasks across many occupations using expert human judgments, often requiring models to produce real work artifacts (e.g., spreadsheets, presentations, plans). It emphasizes end-to-end execution quality, following specifications, and producing usable outputs under practical constraints.","L1: Language Comprehension, Language Production
L2: Planning, Decision-making, Working Memory, Adaptive Error Correction, Semantic Understanding & Context Recognition
L3: Self-reflection, Social Reasoning & Theory of Mind",L3
SWE-Lancer,https://openai.com/index/swe-lancer/,https://arxiv.org/abs/2502.12115,"SWE-Lancer evaluates software engineering ability on challenging, realistic tasks that emphasize agentic problem-solving in repositories (e.g., implementing changes, fixing bugs, and making correct patches). It aims to reflect professional development workflows where selecting the right approach and verifying correctness are crucial.","L1: Language Comprehension, Language Production
L2: Planning, Decision-making, Logical Reasoning, Working Memory, Adaptive Error Correction
L3: ",L2
FrontierMath,https://epoch.ai/frontiermath,https://arxiv.org/abs/2411.04872,"FrontierMath is a benchmark of advanced mathematics problems designed to probe state-of-the-art mathematical reasoning beyond routine competition questions. It emphasizes multi-step derivations, rigorous logical structure, and the ability to navigate unfamiliar problem types with minimal scaffolding.","L1: 
L2: Logical Reasoning, Working Memory, Planning, Semantic Understanding & Context Recognition
L3: Cognitive Flexibility",L3
