Benchmark,Website,Paper,Description,Cognitive Functions
SWE-bench Verified,https://openai.com/index/introducing-swe-bench-verified/,https://arxiv.org/abs/2310.06770,"SWE-bench Verified evaluates an agent’s ability to solve real-world software engineering issues by generating patches that make a repository’s tests pass. The Verified split adds human validation that each task is solvable and that the evaluation reliably checks correctness, reducing false positives from brittle tests.","Planning, Logical Reasoning, Working Memory, Adaptive Error Correction, Language Comprehension (minor), Language Production (minor)"
Terminal-Bench 2.0,https://www.tbench.ai/,,"Terminal-Bench 2.0 measures agent performance on practical command-line tasks (e.g., debugging, setup, data manipulation) executed in real terminal environments under an agent harness. Success requires correct sequences of shell actions with robust handling of tool output, environment state, and errors.","Planning, Decision-making, Adaptive Error Correction, Working Memory, Language Comprehension (minor), Language Production (minor)"
τ2-bench,https://sierra.ai/uk/blog/benchmarking-ai-agents,https://arxiv.org/abs/2406.12045,"τ2-bench evaluates interactive tool-using agents in multi-turn customer-support style environments (e.g., retail, airline, telecom) with policies and APIs. The agent must follow domain rules, gather information, invoke tools appropriately, and maintain consistency across a dialogue while completing the user’s goal.","Decision-making, Planning, Inhibitory Control, Social Reasoning & Theory of Mind, Working Memory, Language Comprehension, Language Production, Empathy (minor)"
ARC-AGI,https://arcprize.org/arc-agi,https://arxiv.org/abs/1911.01547,ARC-AGI tests “fluid” abstract reasoning by asking models to infer transformation rules from a few input–output grid examples and apply them to a new grid. It is designed to reward systematic generalization to novel tasks rather than memorization of fixed problem types.,"Logical Reasoning, Cognitive Flexibility, Spatial Representation & Mapping, Visual Perception, Working Memory, Planning (minor)"
Vending-Bench 2,https://andonlabs.com/evals/vending-bench-2,https://arxiv.org/abs/2502.15840,"Vending-Bench 2 evaluates long-horizon agent coherence by simulating the operation of a vending-machine business over an extended period, scoring by final financial outcome. The agent must manage inventory, pricing, supplier interactions/negotiation, and adapt decisions as conditions change across many steps.","Planning, Decision-making, Reward Mechanisms, Working Memory, Social Reasoning & Theory of Mind (minor), Cognitive Timing & Predictive Modeling (minor)"
Humanity’s Last Exam,https://agi.safe.ai/,https://arxiv.org/abs/2501.14249,"Humanity’s Last Exam is a broad, frontier-knowledge benchmark spanning many academic and professional domains, often including long-form and multimodal questions. It aims to probe difficult reasoning and synthesis under sparse cues, where shallow pattern matching is less reliable.","Language Comprehension, Semantic Understanding & Context Recognition, Logical Reasoning, Working Memory (minor), Scene Understanding & Visual Reasoning (minor), Multisensory Integration (minor)"
AIME 2025,https://matharena.ai/?view=problem&comp=aime--aime_2025,https://arxiv.org/abs/2505.23281,AIME 2025 consists of competition-style mathematics problems requiring multi-step derivations and exact numeric answers. It stresses precise symbolic manipulation and disciplined reasoning under constraints that punish small logical slips.,"Logical Reasoning, Working Memory, Adaptive Error Correction (minor), Planning (minor)"
GPQA Diamond,https://artificialanalysis.ai/evaluations/gpqa-diamond,https://arxiv.org/abs/2311.12022,"GPQA Diamond is a high-difficulty, “Google-proof” multiple-choice science QA benchmark curated to be challenging for non-experts. It emphasizes deep scientific reasoning and careful disambiguation over surface-level recall.","Language Comprehension, Semantic Understanding & Context Recognition, Logical Reasoning, Working Memory (minor)"
MMMLU,https://huggingface.co/datasets/openai/MMMLU,https://arxiv.org/abs/2009.03300,"MMMLU extends broad subject-matter testing to multiple languages, evaluating knowledge and reasoning across many academic topics in multilingual settings. It probes whether models preserve competence and nuance when questions are posed in different languages and cultural contexts.","Language Comprehension, Semantic Understanding & Context Recognition, Logical Reasoning (minor), Working Memory (minor)"
MMMU-Pro,https://mmmu-benchmark.github.io/,https://arxiv.org/abs/2409.02813,"MMMU-Pro evaluates multimodal understanding and reasoning over images paired with text across many disciplines, using a more challenging and updated problem set than earlier MMMU variants. Tasks require integrating visual evidence (plots, diagrams, photos) with textual instructions to produce correct answers.","Visual Perception, Scene Understanding & Visual Reasoning, Multisensory Integration, Spatial Representation & Mapping (minor), Language Comprehension, Logical Reasoning, Working Memory (minor)"
MathArena Apex,https://matharena.ai/?view=problem&comp=apex--apex_2025,https://arxiv.org/abs/2505.23281,MathArena Apex aggregates advanced math problems (often beyond standard competition difficulty) to compare frontier reasoning systems under consistent evaluation rules. It emphasizes long chains of correct deductions and robustness across diverse mathematical subareas.,"Logical Reasoning, Working Memory, Planning (minor), Adaptive Error Correction (minor)"
ScreenShot-Pro,https://gui-agent.github.io/grounding-leaderboard/,https://arxiv.org/abs/2504.07981,"ScreenShot-Pro evaluates “GUI grounding”: answering questions about high-resolution screenshots from software interfaces and dashboards. It requires locating relevant UI elements and interpreting layout, labels, and visual structure to produce correct responses (often aided by precise visual parsing).","Visual Perception, Visual Attention & Eye Movements, Spatial Representation & Mapping, Scene Understanding & Visual Reasoning, Language Comprehension (minor), Sensorimotor Coordination (minor)"
CharXiv Reasoning,https://charxiv.github.io/,https://arxiv.org/abs/2406.18521,"CharXiv Reasoning tests scientific-figure understanding by asking questions grounded in charts and figures from research papers, often requiring quantitative or relational reasoning. Models must extract relevant visual evidence, map it to the question, and perform structured inference to answer.","Scene Understanding & Visual Reasoning, Visual Perception, Logical Reasoning, Semantic Understanding & Context Recognition, Working Memory (minor), Attention (minor)"
OmniDocBench 1.5,https://github.com/opendatalab/OmniDocBench,https://arxiv.org/abs/2412.07626,"OmniDocBench 1.5 evaluates document understanding and OCR-centric extraction across diverse layouts (text, tables, formulas, and reading order). It stresses robustness to complex formatting and requires models to preserve structure when converting documents into usable representations.","Visual Perception, Attention, Scene Understanding & Visual Reasoning, Semantic Understanding & Context Recognition (minor), Working Memory (minor)"
Video-MMMU,https://videommmu.github.io/,https://arxiv.org/abs/2501.13826,"Video-MMMU evaluates multimodal reasoning over video, combining temporal visual information with text questions that may require integrating cues across frames. It targets understanding of events, temporal relationships, and context that cannot be inferred from a single image.","Visual Perception, Multisensory Integration, Cognitive Timing & Predictive Modeling, Scene Understanding & Visual Reasoning, Working Memory, Attention (minor)"
LiveCodeBench Pro,https://livecodebenchpro.com/projects/livecodebench-pro/leaderboard,https://arxiv.org/abs/2506.11928,"LiveCodeBench Pro evaluates coding ability on up-to-date programming problems designed to reduce training-set leakage, often emphasizing practical implementation and correctness. It measures whether a model can reason through problem requirements and produce executable solutions reliably.","Logical Reasoning, Planning, Language Production, Working Memory, Adaptive Error Correction (minor)"
FACTS Benchmark Suite,https://deepmind.google/blog/facts-benchmark-suite-systematically-evaluating-the-factuality-of-large-language-models/,https://arxiv.org/abs/2512.10791,"FACTS Benchmark Suite systematically evaluates factuality by measuring whether model outputs remain grounded and correct across a variety of factuality-focused tasks and settings. It targets error modes like hallucination, unsupported claims, and failures to abstain when uncertain.","Semantic Understanding & Context Recognition, Language Comprehension, Inhibitory Control, Self-reflection (minor), Working Memory (minor)"
SimpleQA Verified,https://www.kaggle.com/benchmarks/deepmind/simpleqa-verified,https://arxiv.org/abs/2509.07968,"SimpleQA Verified is a benchmark of short-form factual questions with verification procedures intended to improve label reliability. It focuses on whether models provide correct, concise factual answers and avoid confidently stating incorrect information.","Semantic Understanding & Context Recognition, Language Comprehension, Inhibitory Control (minor)"
Global PIQA,https://huggingface.co/datasets/mrlbenchmarks/global-piqa-nonparallel,https://arxiv.org/abs/2510.24081,Global PIQA evaluates pragmatic commonsense reasoning across languages by testing whether models can choose or generate plausible physical and everyday-action interpretations in multilingual contexts. It is designed to probe robustness of commonsense inference beyond English-only datasets.,"Semantic Understanding & Context Recognition, Logical Reasoning, Language Comprehension, Cognitive Flexibility (minor)"
MRCR v2 (8-needle),https://huggingface.co/datasets/openai/mrcr,https://arxiv.org/abs/2409.12640,"MRCR v2 (8-needle) is a long-context evaluation where multiple similar “needle” interactions are embedded in a long “haystack,” and the model must retrieve and reproduce the correct response for a specified needle. It stresses maintaining and accessing the right information under interference from many near-duplicate spans.","Working Memory, Attention, Episodic Memory, Language Comprehension, Inhibitory Control (minor)"
