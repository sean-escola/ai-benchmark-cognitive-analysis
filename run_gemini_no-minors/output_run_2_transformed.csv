Benchmark,Website,Paper,Description,Cognitive Functions,Max AI Tier
SWE-bench Pro,https://scale.com/research/swe_bench_pro,https://arxiv.org/abs/2509.16941,"SWE-bench Pro is a large-scale software engineering benchmark where a model must generate patches that resolve real issues in open-source repositories under realistic constraints (tests, dependencies, and project conventions). It expands beyond Python and is designed to be more challenging and more resistant to contamination than earlier SWE-bench variants.","L1: Language Comprehension (minor), Language Production (minor)
L2: Logical Reasoning, Planning, Adaptive Error Correction, Working Memory, Decision-making
L3: ",L2
OSWorld,https://os-world.github.io/,https://arxiv.org/abs/2404.07972,"OSWorld evaluates multimodal “computer use” by requiring an agent to complete tasks in a full desktop operating-system environment using screenshots and UI interactions (e.g., clicking, typing, navigation). Success requires reliably perceiving interfaces, choosing actions over many steps, and recovering from tool/interaction errors.","L1: Visual Perception
L2: Scene Understanding & Visual Reasoning, Visual Attention & Eye Movements, Sensorimotor Coordination, Planning, Decision-making, Working Memory
L3: Inhibitory Control (minor)",L2
ARC-AGI,https://arcprize.org/arc-agi,https://arxiv.org/abs/1911.01547,ARC-AGI is a fluid reasoning benchmark based on abstract grid transformation puzzles where the model must infer a latent rule from a few input–output examples and apply it to a new input. It emphasizes generalization to novel patterns with minimal task-specific prior exposure.,"L1: 
L2: Logical Reasoning, Working Memory, Spatial Representation & Mapping, Attention (minor)
L3: Cognitive Flexibility",L3
Vending-Bench 2,https://andonlabs.com/evals/vending-bench-2,https://arxiv.org/abs/2502.15840,"Vending-Bench 2 measures long-horizon agent performance by simulating operation of a vending machine business over an extended time period, scoring by final balance/profit. The agent must make coherent decisions across many steps, adapting to changing conditions (inventory, suppliers, pricing) without losing goal consistency.","L1: 
L2: Planning, Decision-making, Reward Mechanisms, Working Memory, Adaptive Error Correction, Semantic Understanding & Context Recognition (minor)
L3: Motivational Drives (minor)",L2
MCP-Atlas,https://scale.com/leaderboard/mcp_atlas,,"MCP-Atlas evaluates real-world tool use via the Model Context Protocol by testing whether a model can discover, invoke, and chain tools across multi-step workflows. Tasks require correct API selection, parameterization, error handling, and synthesis of results into a final answer.","L1: Language Comprehension (minor), Language Production (minor)
L2: Planning, Decision-making, Working Memory, Adaptive Error Correction
L3: Inhibitory Control (minor)",L2
CyberGym,https://www.cybergym.io/,https://arxiv.org/abs/2506.02548,"CyberGym evaluates agentic cybersecurity capabilities on tasks grounded in real software vulnerabilities, including identifying known vulnerabilities and, in some settings, discovering new ones. It stresses iterative investigation, hypothesis testing, and producing actionable outputs (e.g., proof-of-concept reasoning or patch-level changes).","L1: Language Comprehension (minor)
L2: Logical Reasoning, Planning, Adaptive Error Correction, Decision-making, Working Memory
L3: ",L2
Humanity’s Last Exam,https://agi.safe.ai/,https://arxiv.org/abs/2501.14249,"Humanity’s Last Exam is a multimodal benchmark of difficult questions intended to sit near the frontier of human knowledge, spanning many domains and often requiring multi-step reasoning. It is commonly evaluated both without tools and with tools (e.g., search and code execution), testing end-to-end problem solving under realistic assistance settings.","L1: Language Comprehension, Visual Perception (minor)
L2: Logical Reasoning, Semantic Understanding & Context Recognition, Working Memory, Scene Understanding & Visual Reasoning (minor)
L3: ",L2
GPQA Diamond,https://artificialanalysis.ai/evaluations/gpqa-diamond,https://arxiv.org/abs/2311.12022,GPQA Diamond is a subset of GPQA consisting of high-quality graduate-level science multiple-choice questions that are designed to be difficult to answer via superficial pattern matching or simple web search. It probes deep conceptual understanding and careful multi-step elimination among plausible distractors.,"L1: Language Comprehension
L2: Logical Reasoning, Semantic Understanding & Context Recognition, Working Memory, Decision-making (minor)
L3: ",L2
MMMU-Pro,https://mmmu-benchmark.github.io/,https://arxiv.org/abs/2409.02813,"MMMU-Pro is a challenging multimodal benchmark covering expert-level questions across diverse disciplines, where models must interpret images (figures, diagrams, charts) alongside text. It emphasizes robust visual grounding and reasoning rather than surface recognition alone.","L1: Visual Perception, Language Comprehension
L2: Scene Understanding & Visual Reasoning, Logical Reasoning, Working Memory, Spatial Representation & Mapping (minor)
L3: ",L2
OmniDocBench 1.5,https://github.com/opendatalab/OmniDocBench,https://arxiv.org/abs/2412.07626,"OmniDocBench 1.5 evaluates document understanding/OCR by measuring how accurately models transcribe and structure content from complex documents (text, tables, formulas, and reading order). It focuses on faithful extraction under layout complexity rather than purely conversational ability.","L1: Visual Perception, Language Comprehension (minor)
L2: Visual Attention & Eye Movements, Scene Understanding & Visual Reasoning, Spatial Representation & Mapping, Working Memory (minor)
L3: ",L2
Video-MMMU,https://videommmu.github.io/,https://arxiv.org/abs/2501.13826,"Video-MMMU extends multimodal evaluation to videos, requiring models to integrate information across time to answer questions about events, actions, and causal/temporal relations. It tests whether an agent can maintain and update hypotheses as new frames provide additional context.","L1: Visual Perception, Language Comprehension (minor), Auditory Processing (minor)
L2: Attention, Working Memory, Scene Understanding & Visual Reasoning
L3: Cognitive Timing & Predictive Modeling",L3
LiveCodeBench Pro,https://livecodebenchpro.com/projects/livecodebench-pro/leaderboard,https://arxiv.org/abs/2506.11928,"LiveCodeBench Pro measures competitive-style coding performance on fresh, time-indexed programming problems, often reported via an ELO-style rating. It targets reliable code synthesis and debugging under constraints that discourage memorization of static benchmark items.","L1: Language Production
L2: Logical Reasoning, Planning, Adaptive Error Correction, Working Memory, Decision-making (minor)
L3: ",L2
FACTS Benchmark Suite,https://deepmind.google/blog/facts-benchmark-suite-systematically-evaluating-the-factuality-of-large-language-models/,https://arxiv.org/abs/2512.10791,"The FACTS Benchmark Suite systematically evaluates factuality by testing whether model outputs remain accurate, appropriately grounded, and resistant to hallucination across multiple factuality-related tasks. It is designed to separate true helpfulness from fluent but unsupported generation.","L1: Language Production
L2: Semantic Understanding & Context Recognition, Working Memory, Adaptive Error Correction (minor)
L3: Inhibitory Control, Self-reflection (minor)",L3
Global PIQA,https://huggingface.co/datasets/mrlbenchmarks/global-piqa-nonparallel,https://arxiv.org/abs/2510.24081,"Global PIQA evaluates physical commonsense and everyday procedural reasoning across many languages, aiming to measure whether models preserve commonsense competence under multilingual expression. Items typically require selecting or generating plausible actions/explanations grounded in basic physical constraints and affordances.","L1: Language Comprehension
L2: Semantic Understanding & Context Recognition, Logical Reasoning, Working Memory (minor)
L3: Cognitive Flexibility (minor)",L2
MRCR v2 (8-needle),https://huggingface.co/datasets/openai/mrcr,https://arxiv.org/abs/2409.12640,"MRCR v2 is a long-context multi-round coreference/retrieval benchmark where multiple similar “needle” interactions are embedded in a large “haystack,” and the model must reproduce the correct response corresponding to a specified needle. The 8-needle variant stresses robustness when many near-duplicate candidates compete for attention across long contexts.","L1: Language Comprehension
L2: Working Memory, Attention, Episodic Memory
L3: Inhibitory Control (minor)",L2
GDPval,https://openai.com/index/gdpval/,https://arxiv.org/abs/2510.04374,"GDPval evaluates economically valuable professional knowledge work by having models produce real work artifacts (e.g., spreadsheets, presentations, schedules) across many occupations, with expert judges comparing outputs to human professionals. It emphasizes end-to-end execution quality, instruction following, and practical decision-making under constraints.","L1: Language Production
L2: Planning, Decision-making, Semantic Understanding & Context Recognition, Working Memory, Adaptive Error Correction (minor)
L3: Social Reasoning & Theory of Mind (minor)",L2
SWE-Lancer,https://openai.com/index/swe-lancer/,https://arxiv.org/abs/2502.12115,"SWE-Lancer is a software engineering evaluation focused on end-to-end task completion in realistic coding workflows, emphasizing producing correct, reviewable changes that satisfy a task specification. It is intended to reflect practical engineering outcomes more directly than isolated coding puzzles.","L1: Language Comprehension (minor), Language Production (minor)
L2: Planning, Adaptive Error Correction, Logical Reasoning, Working Memory, Decision-making
L3: ",L2
FrontierMath,https://epoch.ai/frontiermath,https://arxiv.org/abs/2411.04872,"FrontierMath is a difficult mathematics benchmark targeting advanced, research-adjacent problem solving, often reported by tier to reflect increasing difficulty. It emphasizes sustained multi-step derivations, careful symbolic manipulation, and (when allowed) effective use of computation tools to verify or explore solutions.","L1: 
L2: Logical Reasoning, Working Memory, Planning, Adaptive Error Correction
L3: Cognitive Flexibility (minor), Cognitive Timing & Predictive Modeling (minor)",L2
