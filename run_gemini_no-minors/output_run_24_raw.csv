Benchmark,Website,Paper,Description,Cognitive Functions
SWE-bench Verified,https://openai.com/index/introducing-swe-bench-verified/,https://arxiv.org/abs/2310.06770,"SWE-bench Verified evaluates software-engineering agents on real GitHub issues by asking them to produce a code patch that makes the repository’s tests pass. The Verified subset uses tasks that have been human-checked for solvability and clearer evaluation, emphasizing end-to-end debugging, editing, and validation under realistic constraints.","Planning, Adaptive Error Correction, Logical Reasoning, Working Memory, Language Comprehension (minor), Decision-making (minor)"
Terminal-Bench 2.0,https://www.tbench.ai/,,"Terminal-Bench 2.0 measures an agent’s ability to complete practical tasks in a command-line environment (e.g., file manipulation, package/tool use, scripting, and diagnosing failures). It stresses iterative interaction: interpreting outputs, choosing next commands, and recovering from errors under time/step constraints.","Planning, Decision-making, Adaptive Error Correction, Working Memory, Inhibitory Control (minor), Language Comprehension (minor)"
τ2-bench,https://sierra.ai/uk/blog/benchmarking-ai-agents,https://arxiv.org/abs/2406.12045,"τ2-bench evaluates interactive tool-using customer-support agents in simulated domains (e.g., retail, airline, telecom) that must follow policies while using APIs over multiple turns. It probes robustness to user behavior, policy compliance, and sustained task execution across long dialogues with tool calls.","Social Reasoning & Theory of Mind, Decision-making, Planning, Inhibitory Control, Language Comprehension, Language Production, Working Memory (minor)"
ARC-AGI,https://arcprize.org/arc-agi,https://arxiv.org/abs/1911.01547,"ARC-AGI tests few-shot abstract reasoning on novel grid-based pattern transformation tasks, where models infer hidden rules from a small number of input–output examples. It is designed to emphasize generalization and problem solving under distribution shift rather than memorized domain knowledge.","Cognitive Flexibility, Logical Reasoning, Working Memory, Spatial Representation & Mapping, Scene Understanding & Visual Reasoning, Attention (minor)"
Vending-Bench 2,https://andonlabs.com/evals/vending-bench-2,https://arxiv.org/abs/2502.15840,"Vending-Bench 2 evaluates long-horizon agent competence in a simulated vending-machine business, requiring inventory management, vendor negotiation, pricing, and adaptation over many steps. The score is typically tied to business outcomes (e.g., final balance), rewarding coherent strategy and error recovery over extended trajectories.","Planning, Decision-making, Reward Mechanisms, Adaptive Error Correction, Working Memory, Cognitive Timing & Predictive Modeling (minor), Motivational Drives (minor)"
Humanity’s Last Exam,https://agi.safe.ai/,https://arxiv.org/abs/2501.14249,"Humanity’s Last Exam is a high-difficulty, broad-coverage benchmark intended to approximate frontier academic and professional reasoning across many domains, often including multimodal questions. It emphasizes solving novel, knowledge-intensive problems and integrating information, sometimes with optional tool use depending on the evaluation setup.","Logical Reasoning, Semantic Understanding & Context Recognition, Working Memory, Language Comprehension, Scene Understanding & Visual Reasoning (minor), Visual Perception (minor)"
AIME 2025,https://matharena.ai/?view=problem&comp=aime--aime_2025,https://arxiv.org/abs/2505.23281,"AIME 2025 evaluates competition-style mathematics problem solving on the 2025 AIME set, typically scored by exact final answers. It probes multi-step derivations, algebraic/number-theoretic reasoning, and careful constraint handling under limited context.","Logical Reasoning, Working Memory, Planning, Adaptive Error Correction (minor), Attention (minor)"
GPQA Diamond,https://artificialanalysis.ai/evaluations/gpqa-diamond,https://arxiv.org/abs/2311.12022,"GPQA Diamond is a curated subset of GPQA designed to be especially difficult and resistant to superficial lookup, using graduate-level science multiple-choice questions. It emphasizes deep conceptual understanding and multi-step scientific reasoning rather than rote recall.","Logical Reasoning, Semantic Understanding & Context Recognition, Language Comprehension, Working Memory (minor), Inhibitory Control (minor)"
MMMLU,https://huggingface.co/datasets/openai/MMMLU,https://arxiv.org/abs/2009.03300,"MMMLU extends broad academic knowledge testing to multiple languages, covering many subjects with standardized question formats. It targets cross-lingual generalization and the ability to apply knowledge and reasoning consistently across linguistic contexts.","Language Comprehension, Semantic Understanding & Context Recognition, Logical Reasoning (minor), Working Memory (minor), Language Production (minor)"
MMMU-Pro,https://mmmu-benchmark.github.io/,https://arxiv.org/abs/2409.02813,"MMMU-Pro is a more challenging variant of MMMU for multimodal expert reasoning, combining text with images from diverse disciplines (e.g., charts, diagrams, documents). It emphasizes grounded visual understanding plus domain reasoning, often with stricter protocols to reduce shortcut solving.","Visual Perception, Scene Understanding & Visual Reasoning, Multisensory Integration, Logical Reasoning, Attention (minor), Language Comprehension (minor)"
MathArena Apex,https://matharena.ai/?view=problem&comp=apex--apex_2025,https://arxiv.org/abs/2505.23281,"MathArena Apex is a hard mathematics benchmark collection intended to stress advanced problem solving beyond standard contest questions, often evaluated with consistent prompting and scoring across models. It prioritizes difficult multi-step reasoning, proof-like planning, and robustness to tricky edge cases.","Logical Reasoning, Planning, Working Memory, Adaptive Error Correction (minor), Attention (minor)"
ScreenShot-Pro,https://gui-agent.github.io/grounding-leaderboard/,https://arxiv.org/abs/2504.07981,"ScreenShot-Pro evaluates GUI understanding and grounding from screenshots, typically requiring models to identify interface elements, interpret layout, and answer questions or propose actions based on what is visible. It stresses high-resolution visual reading, spatial reasoning over UI structure, and mapping intent to interface affordances.","Visual Perception, Visual Attention & Eye Movements, Spatial Representation & Mapping, Scene Understanding & Visual Reasoning, Planning (minor), Decision-making (minor)"
CharXiv Reasoning,https://charxiv.github.io/,https://arxiv.org/abs/2406.18521,"CharXiv Reasoning tests reasoning over figures from scientific papers (e.g., plots, diagrams, and experimental results) paired with questions that require interpretation and inference. It emphasizes extracting quantitative/structural information from visuals and integrating it with scientific context in text.","Scene Understanding & Visual Reasoning, Visual Perception, Semantic Understanding & Context Recognition, Logical Reasoning, Working Memory (minor), Attention (minor)"
OmniDocBench 1.5,https://github.com/opendatalab/OmniDocBench,https://arxiv.org/abs/2412.07626,"OmniDocBench 1.5 evaluates document understanding and OCR-centric capabilities across heterogeneous layouts, including text blocks, tables, formulas, and reading order. Scores commonly reflect edit distance or structure-aware metrics, emphasizing faithful extraction and layout-aware interpretation.","Visual Perception, Scene Understanding & Visual Reasoning, Attention, Language Comprehension (minor), Spatial Representation & Mapping (minor)"
Video-MMMU,https://videommmu.github.io/,https://arxiv.org/abs/2501.13826,"Video-MMMU extends multimodal reasoning to video, requiring models to answer questions that depend on temporal visual information (events, actions, and scene changes) along with accompanying text. It emphasizes integrating cues across frames and maintaining coherence over time.","Visual Perception, Multisensory Integration, Working Memory, Cognitive Timing & Predictive Modeling, Scene Understanding & Visual Reasoning, Attention (minor)"
LiveCodeBench Pro,https://livecodebenchpro.com/projects/livecodebench-pro/leaderboard,https://arxiv.org/abs/2506.11928,"LiveCodeBench Pro evaluates code generation and problem solving on programming tasks designed for strong contamination resistance and realistic difficulty, often using hidden or time-split test sets. It focuses on producing correct, executable solutions under single-try constraints and diverse problem types.","Logical Reasoning, Planning, Adaptive Error Correction, Working Memory, Language Comprehension (minor), Language Production (minor)"
FACTS Benchmark Suite,https://deepmind.google/blog/facts-benchmark-suite-systematically-evaluating-the-factuality-of-large-language-models/,https://arxiv.org/abs/2512.10791,"FACTS Benchmark Suite measures factuality and grounding of model outputs across multiple subtests that probe whether responses align with provided evidence and real-world facts. It emphasizes detecting and avoiding hallucinations, maintaining consistency, and appropriately expressing uncertainty when information is missing.","Semantic Understanding & Context Recognition, Inhibitory Control, Self-reflection, Language Comprehension (minor), Language Production (minor), Working Memory (minor)"
SimpleQA Verified,https://www.kaggle.com/benchmarks/deepmind/simpleqa-verified,https://arxiv.org/abs/2509.07968,SimpleQA Verified is a short-form factual question answering benchmark with verification procedures aimed at reducing annotation noise and improving reliability of correctness labels. It targets precise retrieval-like knowledge and the ability to avoid confidently stating incorrect facts.,"Semantic Understanding & Context Recognition, Inhibitory Control, Language Comprehension (minor), Self-reflection (minor)"
Global PIQA,https://huggingface.co/datasets/mrlbenchmarks/global-piqa-nonparallel,https://arxiv.org/abs/2510.24081,"Global PIQA evaluates physical commonsense reasoning across many languages using non-parallel or culturally varied formulations, aiming to test whether models can generalize practical “how-to”/affordance knowledge beyond English. It emphasizes grounded reasoning about everyday physical interactions and plausible outcomes.","Logical Reasoning, Semantic Understanding & Context Recognition, Cognitive Flexibility (minor), Spatial Representation & Mapping (minor), Sensorimotor Coordination (minor), Language Comprehension (minor)"
MRCR v2 (8-needle),https://huggingface.co/datasets/openai/mrcr,https://arxiv.org/abs/2409.12640,"MRCR v2 (8-needle) tests long-context multi-round co-reference and retrieval by embedding multiple similar “needle” interactions within long “haystack” conversations and asking models to reproduce the correct referenced content. The 8-needle setting stresses sustained attention, interference resistance, and accurate recall under heavy distractors.","Working Memory, Attention, Episodic Memory, Inhibitory Control, Language Comprehension, Cognitive Timing & Predictive Modeling (minor)"
