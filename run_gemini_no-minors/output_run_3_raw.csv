Benchmark,Website,Paper,Description,Cognitive Functions
SWE-bench Pro,https://scale.com/research/swe_bench_pro,https://arxiv.org/abs/2509.16941,"SWE-bench Pro evaluates software engineering agents on large-scale, real-world repo tasks that require producing correct patches under realistic project constraints. Compared with SWE-bench Verified, it is broader and more difficult, aiming for stronger contamination resistance and more industrially relevant task diversity across multiple languages.","Planning, Adaptive Error Correction, Logical Reasoning, Working Memory, Language Comprehension (minor), Language Production (minor)"
OSWorld,https://os-world.github.io/,https://arxiv.org/abs/2404.07972,"OSWorld measures computer-use agency in a full operating-system environment, where models must interpret GUIs and execute multi-step tasks (e.g., browsing, settings changes, file operations). It stresses end-to-end perception–cognition–action loops with tool/interface interaction, including recovery from errors and changing states.","Visual Perception, Scene Understanding & Visual Reasoning, Planning, Decision-making, Attention, Working Memory, Sensorimotor Coordination (minor), Adaptive Error Correction (minor)"
ARC-AGI,https://arcprize.org/arc-agi,https://arxiv.org/abs/1911.01547,"ARC-AGI tests “fluid intelligence” via grid-based puzzles: given a few input-output examples, a system must infer the hidden transformation and apply it to a new input. It is designed to emphasize generalization to novel rules over memorization and to reward compact, correct abstractions from scarce data.","Logical Reasoning, Cognitive Flexibility, Working Memory, Spatial Representation & Mapping, Visual Perception (minor), Attention (minor)"
Vending-Bench 2,https://andonlabs.com/evals/vending-bench-2,https://arxiv.org/abs/2502.15840,"Vending-Bench 2 evaluates long-horizon autonomous agency in a simulated year-long business management setting (running a vending machine operation with suppliers, pricing, inventory, and cash flow). High scores require sustained coherence across thousands of decisions, strategic adaptation to markets, and effective communication/negotiation behaviors.","Planning, Decision-making, Working Memory, Reward Mechanisms, Semantic Understanding & Context Recognition, Social Reasoning & Theory of Mind (minor), Language Production (minor)"
MCP-Atlas,https://scale.com/leaderboard/mcp_atlas,,"MCP-Atlas measures real-world tool use through the Model Context Protocol, emphasizing multi-step workflows: discovering tools, calling them with correct arguments, handling failures, and synthesizing results. Tasks resemble production integrations where robustness and correct orchestration matter more than single-turn knowledge.","Planning, Decision-making, Working Memory, Adaptive Error Correction, Language Comprehension (minor), Language Production (minor), Semantic Understanding & Context Recognition (minor)"
CyberGym,https://www.cybergym.io/,https://arxiv.org/abs/2506.02548,"CyberGym evaluates cybersecurity agent capability on tasks involving finding known vulnerabilities and discovering new ones in real open-source codebases, often from high-level vulnerability descriptions. It stresses structured investigation, code understanding, hypothesis testing, and correct exploit/patch reasoning under realistic constraints.","Logical Reasoning, Planning, Working Memory, Adaptive Error Correction, Semantic Understanding & Context Recognition, Inhibitory Control (minor)"
Humanity’s Last Exam,https://agi.safe.ai/,https://arxiv.org/abs/2501.14249,"Humanity’s Last Exam is a large, frontier-difficulty benchmark spanning many domains (often including multimodal items) intended to probe expert-level knowledge and reasoning at the edge of current models. Performance depends on integrating domain knowledge with careful multi-step inference and, in some settings, tool-mediated problem solving.","Language Comprehension, Logical Reasoning, Working Memory, Semantic Understanding & Context Recognition, Scene Understanding & Visual Reasoning (minor), Planning (minor)"
GPQA Diamond,https://artificialanalysis.ai/evaluations/gpqa-diamond,https://arxiv.org/abs/2311.12022,"GPQA Diamond is a hard subset of graduate-level science multiple-choice questions curated to be “Google-proof,” where non-experts tend to fail and experts tend to succeed. It targets deep conceptual understanding and careful reasoning rather than shallow pattern matching or rote facts.","Logical Reasoning, Semantic Understanding & Context Recognition, Working Memory, Language Comprehension, Inhibitory Control (minor)"
MMMU-Pro,https://mmmu-benchmark.github.io/,https://arxiv.org/abs/2409.02813,"MMMU-Pro extends multimodal academic reasoning evaluation with harder questions requiring interpretation of images (charts, diagrams, scientific figures) alongside text. It emphasizes cross-domain, multi-discipline problem solving where the model must ground symbolic reasoning in visual evidence.","Visual Perception, Scene Understanding & Visual Reasoning, Multisensory Integration, Logical Reasoning, Working Memory, Visual Attention & Eye Movements (minor), Language Comprehension (minor)"
OmniDocBench 1.5,https://github.com/opendatalab/OmniDocBench,https://arxiv.org/abs/2412.07626,"OmniDocBench 1.5 evaluates document understanding and OCR-centric extraction across diverse layouts, including text blocks, tables, formulas, and reading order. It tests whether models can accurately perceive, parse, and reconstruct structured information from complex document images.","Visual Perception, Scene Understanding & Visual Reasoning, Attention, Working Memory (minor), Language Comprehension (minor), Spatial Representation & Mapping (minor)"
Video-MMMU,https://videommmu.github.io/,https://arxiv.org/abs/2501.13826,"Video-MMMU evaluates multimodal understanding and reasoning over video, requiring integration of temporal visual evidence with language prompts. Tasks commonly depend on tracking events, objects, and causal relationships across time rather than single-frame recognition.","Visual Perception, Scene Understanding & Visual Reasoning, Cognitive Timing & Predictive Modeling, Working Memory, Multisensory Integration (minor), Attention (minor)"
LiveCodeBench Pro,https://livecodebenchpro.com/projects/livecodebench-pro/leaderboard,https://arxiv.org/abs/2506.11928,"LiveCodeBench Pro measures coding ability on time-split, competition-style programming tasks with execution-based grading, designed to reduce leakage from widely circulated solutions. It tests whether models can synthesize correct algorithms and produce runnable code under constraints typical of real coding interviews/contests.","Logical Reasoning, Planning, Working Memory, Adaptive Error Correction, Language Production, Language Comprehension (minor)"
FACTS Benchmark Suite,https://deepmind.google/blog/facts-benchmark-suite-systematically-evaluating-the-factuality-of-large-language-models/,https://arxiv.org/abs/2512.10791,"FACTS Benchmark Suite systematically evaluates factuality by testing whether model outputs stay grounded in sources and avoid unsupported claims across multiple factuality-related subtests. It targets reliability under realistic prompting where models must distinguish known facts, uncertainty, and source-constrained generation.","Semantic Understanding & Context Recognition, Language Comprehension, Language Production, Inhibitory Control, Working Memory (minor), Self-reflection (minor)"
Global PIQA,https://huggingface.co/datasets/mrlbenchmarks/global-piqa-nonparallel,https://arxiv.org/abs/2510.24081,"Global PIQA evaluates pragmatic commonsense and “what would work” physical reasoning across many languages and cultural contexts using non-parallel (not direct translations) items. It aims to measure robust, globally applicable practical inference rather than English-centric artifacts.","Semantic Understanding & Context Recognition, Logical Reasoning, Language Comprehension, Social Reasoning & Theory of Mind (minor), Cognitive Flexibility (minor)"
MRCR v2 (8-needle),https://huggingface.co/datasets/openai/mrcr,https://arxiv.org/abs/2409.12640,"MRCR v2 (8-needle) is a long-context evaluation where multiple similar “needle” requests are embedded in long “haystacks,” and the model must retrieve the correct response corresponding to a specified needle. It stresses robust cross-document co-reference and precise information selection over very long contexts.","Working Memory, Attention, Language Comprehension, Semantic Understanding & Context Recognition, Episodic Memory (minor)"
GDPval,https://openai.com/index/gdpval/,https://arxiv.org/abs/2510.04374,"GDPval evaluates economically valuable, well-specified knowledge work across many occupations, scoring outputs via expert human judgment (often through head-to-head comparisons). Tasks frequently require producing professional artifacts (e.g., spreadsheets, presentations, plans) under clear constraints and quality standards.","Planning, Decision-making, Language Production, Semantic Understanding & Context Recognition, Working Memory, Social Reasoning & Theory of Mind (minor)"
SWE-Lancer,https://openai.com/index/swe-lancer/,https://arxiv.org/abs/2502.12115,"SWE-Lancer evaluates agentic software engineering on realistic tasks that resemble contracted development work, emphasizing end-to-end delivery quality rather than isolated code snippets. It rewards correct changes, adherence to task intent, and practical robustness when working with real repositories and requirements.","Planning, Logical Reasoning, Adaptive Error Correction, Working Memory, Decision-making (minor), Language Comprehension (minor)"
FrontierMath,https://epoch.ai/frontiermath,https://arxiv.org/abs/2411.04872,"FrontierMath measures expert-level mathematics by using newly created or carefully curated problems intended to be difficult for current models and resistant to memorization. It probes multi-step derivations, precise symbolic manipulation, and the ability to sustain correct reasoning over long solution paths.","Logical Reasoning, Working Memory, Planning, Cognitive Flexibility (minor), Attention (minor)"
