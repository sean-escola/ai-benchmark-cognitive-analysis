Benchmark,Website,Paper,Description,Cognitive Functions,Max AI Tier
SWE-bench Pro,https://scale.com/research/swe_bench_pro,https://arxiv.org/abs/2509.16941,"SWE-bench Pro evaluates software engineering agents on realistic, repo-level issues that require producing correct code patches in real projects. It emphasizes longer, more contamination-resistant and industrially relevant tasks than SWE-bench Verified, including multiple programming languages and complex dependency/test setups.","L1: Language Comprehension (minor), Language Production (minor)
L2: Planning, Adaptive Error Correction, Logical Reasoning, Working Memory, Decision-making
L3: ",L2
OSWorld,https://os-world.github.io/,https://arxiv.org/abs/2404.07972,"OSWorld benchmarks multimodal “computer use” agents that must complete tasks by operating a desktop environment (e.g., using apps, dialogs, file systems, and web UIs) under step and time constraints. It stresses perception-to-action grounding: interpreting screenshots, choosing UI actions, and recovering from mistakes in an interactive environment.","L1: Visual Perception
L2: Scene Understanding & Visual Reasoning, Planning, Decision-making, Attention, Sensorimotor Coordination (minor), Adaptive Error Correction (minor)
L3: ",L2
ARC-AGI,https://arcprize.org/arc-agi,https://arxiv.org/abs/1911.01547,"ARC-AGI measures fluid, novel pattern induction from a few input–output grid examples, requiring generalization to a new grid rather than retrieval of known facts. Tasks are designed to be solvable by humans with abstract reasoning and minimal training data, emphasizing compositional rules and out-of-distribution generalization.","L1: 
L2: Logical Reasoning, Working Memory, Spatial Representation & Mapping, Scene Understanding & Visual Reasoning, Planning (minor)
L3: Cognitive Flexibility",L3
Vending-Bench 2,https://andonlabs.com/evals/vending-bench-2,https://arxiv.org/abs/2502.15840,"Vending-Bench 2 evaluates long-horizon agent coherence by simulating management of a vending-machine business over an extended period (e.g., a year), with many sequential decisions affecting profit. High performance requires sustained strategy, inventory/pricing decisions, adaptation to changing conditions, and error recovery across thousands of steps.","L1: 
L2: Planning, Decision-making, Reward Mechanisms, Working Memory, Adaptive Error Correction (minor), Episodic Memory (minor)
L3: Social Reasoning & Theory of Mind (minor)",L2
MCP-Atlas,https://scale.com/leaderboard/mcp_atlas,,"MCP-Atlas measures real-world tool use via the Model Context Protocol (MCP), requiring models to discover tools, call them correctly, and compose multi-step workflows across tool servers. It stresses reliable API interaction, error handling, and synthesis of tool outputs into a correct final response.","L1: Language Comprehension (minor), Language Production (minor)
L2: Planning, Decision-making, Working Memory, Adaptive Error Correction
L3: ",L2
CyberGym,https://www.cybergym.io/,https://arxiv.org/abs/2506.02548,"CyberGym evaluates cybersecurity agents on tasks such as identifying known vulnerabilities in real codebases from high-level descriptions and discovering new vulnerabilities. Success typically requires reasoning about program behavior, navigating code, forming hypotheses, and iteratively testing/fixing in a realistic workflow.","L1: Language Comprehension (minor)
L2: Logical Reasoning, Planning, Adaptive Error Correction, Working Memory, Decision-making
L3: ",L2
Humanity’s Last Exam,https://agi.safe.ai/,https://arxiv.org/abs/2501.14249,"Humanity’s Last Exam is a difficult multimodal benchmark intended to probe frontier academic knowledge and reasoning across many domains with hard, expert-level questions. It is designed to be challenging for models even with strong general capabilities, emphasizing careful reasoning and resisting superficial pattern matching.","L1: Language Comprehension, Visual Perception (minor)
L2: Logical Reasoning, Semantic Understanding & Context Recognition, Working Memory, Scene Understanding & Visual Reasoning (minor)
L3: ",L2
GPQA Diamond,https://artificialanalysis.ai/evaluations/gpqa-diamond,https://arxiv.org/abs/2311.12022,"GPQA Diamond is a curated subset of graduate-level, “Google-proof” multiple-choice science questions where non-experts typically fail, emphasizing deep scientific understanding. It tests whether models can reason through difficult physics/chemistry/biology questions rather than relying on shallow recall.","L1: Language Comprehension
L2: Logical Reasoning, Semantic Understanding & Context Recognition, Working Memory
L3: ",L2
MMMU-Pro,https://mmmu-benchmark.github.io/,https://arxiv.org/abs/2409.02813,"MMMU-Pro evaluates multimodal understanding and reasoning across many disciplines using images (e.g., diagrams, charts, figures) paired with text questions. It stresses integrating visual evidence with domain knowledge to perform multi-step reasoning, often under multiple-choice constraints.","L1: Visual Perception, Language Comprehension
L2: Scene Understanding & Visual Reasoning, Multisensory Integration, Logical Reasoning, Working Memory
L3: ",L2
OmniDocBench 1.5,https://github.com/opendatalab/OmniDocBench,https://arxiv.org/abs/2412.07626,"OmniDocBench 1.5 measures document understanding quality, including OCR and structured extraction across text, tables, formulas, and reading order. It targets end-to-end comprehension of complex page layouts where correct interpretation depends on spatial structure and cross-element consistency.","L1: Visual Perception
L2: Scene Understanding & Visual Reasoning, Semantic Understanding & Context Recognition, Working Memory (minor), Visual Attention & Eye Movements (minor)
L3: ",L2
Video-MMMU,https://videommmu.github.io/,https://arxiv.org/abs/2501.13826,"Video-MMMU evaluates multimodal reasoning over video, requiring models to answer questions that depend on events, actions, and context evolving across frames. It emphasizes temporal integration, tracking entities over time, and combining visual evidence with language understanding.","L1: Visual Perception, Language Comprehension
L2: Scene Understanding & Visual Reasoning, Working Memory, Attention, Multisensory Integration (minor)
L3: Cognitive Timing & Predictive Modeling",L3
LiveCodeBench Pro,https://livecodebenchpro.com/projects/livecodebench-pro/leaderboard,https://arxiv.org/abs/2506.11928,"LiveCodeBench Pro measures coding ability on time-aligned programming tasks, often emphasizing realistic constraints and evaluating solutions via execution and/or competitive-style scoring (e.g., Elo). It probes the full loop of understanding a problem statement, designing an approach, and producing correct, runnable code under strict correctness requirements.","L1: Language Production, Language Comprehension (minor)
L2: Logical Reasoning, Planning, Adaptive Error Correction, Working Memory
L3: ",L2
FACTS Benchmark Suite,https://deepmind.google/blog/facts-benchmark-suite-systematically-evaluating-the-factuality-of-large-language-models/,https://arxiv.org/abs/2512.10791,"The FACTS Benchmark Suite systematically evaluates factuality-related behavior, including whether outputs remain grounded and avoid introducing unsupported claims across varied settings. It targets reliability failures such as hallucinations and ungrounded extrapolations, often requiring careful attribution and constraint-following.","L1: Language Comprehension, Language Production
L2: Semantic Understanding & Context Recognition, Working Memory (minor)
L3: Inhibitory Control, Self-reflection (minor)",L3
Global PIQA,https://huggingface.co/datasets/mrlbenchmarks/global-piqa-nonparallel,https://arxiv.org/abs/2510.24081,"Global PIQA extends physical commonsense reasoning evaluation across many languages, using non-parallel multilingual variants to reduce translation artifacts. It tests whether models can apply everyday intuitive physics and practical reasoning consistently across diverse linguistic contexts.","L1: Language Comprehension
L2: Logical Reasoning, Semantic Understanding & Context Recognition, Working Memory (minor)
L3: Cognitive Flexibility (minor)",L2
MRCR v2 (8-needle),https://huggingface.co/datasets/openai/mrcr,https://arxiv.org/abs/2409.12640,"MRCR v2 (8-needle) is a long-context multi-round coreference/retrieval-style evaluation where multiple similar “needle” interactions are embedded inside long “haystack” contexts, and the model must reproduce the correct response associated with a specified needle. It stresses robust attention over long inputs, interference resistance, and accurate retrieval of the right instance among distractors.","L1: Language Comprehension
L2: Working Memory, Attention, Semantic Understanding & Context Recognition, Episodic Memory (minor)
L3: Inhibitory Control (minor)",L2
GDPval,https://openai.com/index/gdpval/,https://arxiv.org/abs/2510.04374,"GDPval evaluates economically valuable, well-specified professional knowledge work across many occupations via side-by-side comparisons judged against industry professionals. Tasks often require producing structured artifacts (e.g., spreadsheets, presentations, plans) and coordinating multiple substeps under clear requirements.","L1: Language Production
L2: Planning, Decision-making, Semantic Understanding & Context Recognition, Working Memory
L3: Self-reflection (minor), Social Reasoning & Theory of Mind (minor)",L2
SWE-Lancer,https://openai.com/index/swe-lancer/,https://arxiv.org/abs/2502.12115,"SWE-Lancer evaluates software engineering performance on realistic development work that typically involves interpreting requirements, navigating codebases, and producing correct changes that integrate with existing systems. It emphasizes end-to-end engineering competence, including solution design choices, implementation, and debugging within repo constraints.","L1: Language Comprehension (minor), Language Production (minor)
L2: Planning, Adaptive Error Correction, Logical Reasoning, Working Memory, Decision-making
L3: ",L2
FrontierMath,https://epoch.ai/frontiermath,https://arxiv.org/abs/2411.04872,"FrontierMath measures advanced mathematical problem solving at or beyond typical competition/early-research difficulty, emphasizing rigorous reasoning rather than recall. Problems often require multi-step derivations, careful handling of edge cases, and sustained attention to constraints to reach a correct final result.","L1: 
L2: Logical Reasoning, Working Memory, Planning, Adaptive Error Correction (minor)
L3: Cognitive Flexibility (minor)",L2
