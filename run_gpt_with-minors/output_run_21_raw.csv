Benchmark,Website,Paper,Description,Cognitive Functions
Terminal-Bench 2.0,https://www.tbench.ai/,,"Terminal-Bench 2.0 evaluates agentic coding and sysadmin-style tasks in real terminal environments (e.g., navigating repos, running commands, debugging, and modifying files) under a fixed harness. It emphasizes end-to-end task completion where intermediate tool outputs must be interpreted correctly and used to decide the next command.","Planning, Decision-making, Adaptive Error Correction, Working Memory, Language Comprehension"
BrowseComp,https://openai.com/index/browsecomp/,https://arxiv.org/abs/2504.12516,"BrowseComp measures deep information-seeking over the web (or a controlled web corpus), requiring models to search, read, cross-check sources, and synthesize answers. Success depends on decomposing research questions into sub-queries and integrating evidence across multiple pages and tool calls.","Planning, Attention, Language Comprehension, Semantic Understanding & Context Recognition, Working Memory, Decision-making"
OSWorld,https://os-world.github.io/,https://arxiv.org/abs/2404.07972,"OSWorld evaluates computer-use agents that operate graphical desktop environments to accomplish multi-step tasks across real applications. It stresses perception of UI state from screenshots, grounding actions in interface affordances, and recovering from mistakes across long trajectories.","Visual Perception, Visual Attention & Eye Movements, Planning, Decision-making, Sensorimotor Coordination, Adaptive Error Correction"
ARC-AGI,https://arcprize.org/arc-agi,https://arxiv.org/abs/1911.01547,"ARC-AGI tests fluid reasoning by asking models to infer hidden transformations from a few input–output grid examples and apply them to a new grid. It is designed to minimize reliance on memorized knowledge and instead probe abstraction, generalization, and robust pattern induction.","Logical Reasoning, Cognitive Flexibility, Working Memory, Visual Perception, Spatial Representation & Mapping"
Vending-Bench 2,https://andonlabs.com/evals/vending-bench-2,https://arxiv.org/abs/2502.15840,"Vending-Bench 2 evaluates long-horizon agent coherence by simulating the operation of a vending-machine business over an extended period with many sequential decisions. Models must manage inventory, negotiate with suppliers, set pricing, and adapt to market dynamics to maximize final balance.","Planning, Decision-making, Reward Mechanisms, Working Memory, Adaptive Error Correction, Semantic Understanding & Context Recognition"
CyberGym,https://www.cybergym.io/,https://arxiv.org/abs/2506.02548,"CyberGym evaluates cybersecurity capability on real-world vulnerability tasks at scale, including identifying known vulnerabilities from descriptions and discovering new issues in codebases. It requires carefully reading code and logs, forming hypotheses about failure modes, and validating fixes or exploits with tools.","Logical Reasoning, Planning, Adaptive Error Correction, Working Memory, Language Comprehension"
SpreadsheetBench,https://spreadsheetbench.github.io/,https://arxiv.org/abs/2406.14991,"SpreadsheetBench measures an agent’s ability to understand and manipulate spreadsheets to solve realistic tasks (e.g., cleaning data, editing formulas, generating summaries, and producing correct outputs). It stresses structured reasoning over tabular layouts and precise execution of multi-step edits.","Logical Reasoning, Working Memory, Attention, Planning, Adaptive Error Correction"
Humanity’s Last Exam,https://agi.safe.ai/,https://arxiv.org/abs/2501.14249,"Humanity’s Last Exam is a multimodal benchmark of frontier knowledge and reasoning, spanning difficult questions where shallow pattern matching tends to fail. It typically demands integrating domain expertise with careful reasoning, and (in tool-enabled settings) verifying with search or code.","Language Comprehension, Language Production, Logical Reasoning, Semantic Understanding & Context Recognition, Visual Perception, Working Memory"
GPQA Diamond,https://artificialanalysis.ai/evaluations/gpqa-diamond,https://arxiv.org/abs/2311.12022,"GPQA Diamond is a high-quality subset of extremely challenging, graduate-level science multiple-choice questions intended to be “Google-proof.” It targets deep scientific understanding and careful multi-step reasoning rather than surface recall.","Logical Reasoning, Semantic Understanding & Context Recognition, Working Memory, Language Comprehension"
MMMU-Pro,https://mmmu-benchmark.github.io/,https://arxiv.org/abs/2409.02813,"MMMU-Pro evaluates expert-level multimodal understanding and reasoning across many disciplines using images paired with questions, often in exam-like formats. It probes whether models can extract salient visual details (e.g., diagrams, charts, instruments) and combine them with domain reasoning to choose correct answers.","Visual Perception, Scene Understanding & Visual Reasoning, Language Comprehension, Logical Reasoning, Visual Attention & Eye Movements, Working Memory"
MathArena Apex,https://matharena.ai/?view=problem&comp=apex--apex_2025,https://arxiv.org/abs/2505.23281,"MathArena Apex aggregates hard mathematical reasoning problems under a standardized evaluation interface, focusing on robust problem solving rather than short tricks. It emphasizes multi-step derivations, error checking, and consistency under challenging distributions.","Logical Reasoning, Working Memory, Planning, Adaptive Error Correction, Cognitive Flexibility"
CharXiv Reasoning,https://charxiv.github.io/,https://arxiv.org/abs/2406.18521,"CharXiv Reasoning evaluates scientific figure understanding and reasoning from research-paper-style charts/figures, often requiring quantitative interpretation and multi-step inference. In tool-enabled variants, models may use code to compute values or validate hypotheses derived from the figure.","Visual Perception, Scene Understanding & Visual Reasoning, Logical Reasoning, Language Comprehension, Working Memory, Planning"
OmniDocBench 1.5,https://github.com/opendatalab/OmniDocBench,https://arxiv.org/abs/2412.07626,"OmniDocBench 1.5 measures document understanding and OCR quality across complex layouts, including text blocks, formulas, tables, and reading order. It emphasizes faithful extraction and structural reconstruction rather than only recognizing isolated text.","Visual Perception, Visual Attention & Eye Movements, Language Comprehension, Semantic Understanding & Context Recognition, Working Memory"
Video-MMMU,https://videommmu.github.io/,https://arxiv.org/abs/2501.13826,"Video-MMMU evaluates multimodal reasoning over videos, requiring models to track events, objects, and states across time and answer questions that depend on temporal context. It stresses integration of visual evidence across frames and maintaining coherent situation models over sequences.","Visual Perception, Scene Understanding & Visual Reasoning, Working Memory, Cognitive Timing & Predictive Modeling, Attention"
LiveCodeBench Pro,https://livecodebenchpro.com/projects/livecodebench-pro/leaderboard,https://arxiv.org/abs/2506.11928,"LiveCodeBench Pro evaluates competitive-programming and practical coding ability using fresh, execution-verified tasks and emphasizes strong generalization. It measures whether models can design algorithms, implement correct code, and iteratively fix failures under realistic constraints.","Logical Reasoning, Planning, Adaptive Error Correction, Working Memory, Language Comprehension"
FACTS Benchmark Suite,https://deepmind.google/blog/facts-benchmark-suite-systematically-evaluating-the-factuality-of-large-language-models/,https://arxiv.org/abs/2512.10791,"FACTS Benchmark Suite systematically evaluates factuality and grounding behaviors, probing whether models avoid hallucinations and maintain consistency with provided or implied evidence. It targets reliability in long-form responses where many individual claims must remain correct.","Semantic Understanding & Context Recognition, Language Production, Language Comprehension, Inhibitory Control, Working Memory"
Global PIQA,https://huggingface.co/datasets/mrlbenchmarks/global-piqa-nonparallel,https://arxiv.org/abs/2510.24081,"Global PIQA evaluates physical commonsense reasoning across many languages and cultures using non-parallel items, aiming to reduce English-centric artifacts. It probes whether models can select plausible actions/outcomes in everyday physical scenarios under multilingual variation.","Language Comprehension, Logical Reasoning, Semantic Understanding & Context Recognition, Cognitive Flexibility"
MRCR v2 (8-needle),https://huggingface.co/datasets/openai/mrcr,https://arxiv.org/abs/2409.12640,"MRCR v2 (8-needle) is a long-context evaluation where multiple similar “needle” turns are embedded in large “haystack” conversations, and the model must retrieve the correct response associated with a specified needle. It stresses precise multi-round coreference and robust retrieval under heavy distractors.","Working Memory, Attention, Episodic Memory, Language Comprehension"
GDPval,https://openai.com/index/gdpval/,https://arxiv.org/abs/2510.04374,"GDPval measures performance on well-specified professional knowledge-work tasks across many occupations, judged by expert humans via head-to-head comparisons. It emphasizes producing usable work artifacts (e.g., slides, spreadsheets, plans) that meet real constraints and quality standards.","Planning, Decision-making, Language Production, Semantic Understanding & Context Recognition, Working Memory, Self-reflection"
SWE-Lancer,https://openai.com/index/swe-lancer/,https://arxiv.org/abs/2502.12115,"SWE-Lancer evaluates agentic software engineering on tasks resembling freelance or contract work, where the model must interpret requirements, modify codebases, and deliver correct patches. It emphasizes end-to-end delivery quality, including navigating ambiguity and validating solutions.","Planning, Decision-making, Adaptive Error Correction, Logical Reasoning, Language Comprehension, Working Memory, Language Production"
Graphwalks,https://huggingface.co/datasets/openai/graphwalks,,"Graphwalks evaluates long-context structured reasoning over graph traversal problems (e.g., following edges, reaching targets, or answering queries about paths) presented in text form. It stresses maintaining state over many steps and avoiding drift under distractors.","Spatial Representation & Mapping, Logical Reasoning, Working Memory, Attention"
Toolathon,https://toolathlon.xyz,https://arxiv.org/abs/2510.25726,"Toolathon evaluates general tool-use competence across diverse tool APIs and multi-step workflows, focusing on whether models can select, call, and chain tools correctly to solve tasks. It stresses robustness to tool errors, iterative refinement, and producing final answers grounded in tool outputs.","Planning, Decision-making, Adaptive Error Correction, Working Memory, Language Comprehension"
FrontierMath,https://epoch.ai/frontiermath,https://arxiv.org/abs/2411.04872,"FrontierMath is a collection of very difficult mathematics problems intended to sit near the boundary of current model capability, with strong controls to reduce contamination. It emphasizes deep multi-step reasoning and (in tool-enabled settings) careful verification of derived results.","Logical Reasoning, Working Memory, Planning, Cognitive Flexibility, Adaptive Error Correction"
