Benchmark,Website,Paper,Description,Cognitive Functions
Terminal-Bench 2.0,https://www.tbench.ai/,,"Terminal-Bench 2.0 evaluates agentic coding and system-operation ability in a real command-line environment. Tasks require issuing shell commands, inspecting outputs, editing files, and iterating until the terminal state satisfies a goal, emphasizing robust execution under partial observability and tooling constraints.","Planning, Decision-making, Adaptive Error Correction, Working Memory, Language Comprehension"
BrowseComp,https://openai.com/index/browsecomp/,https://arxiv.org/abs/2504.12516,"BrowseComp measures an agent’s ability to answer difficult, web-style information-seeking questions that typically require multi-step search and synthesis. It stresses planning a retrieval strategy, tracking evidence across sources, and producing a final grounded answer.","Planning, Decision-making, Working Memory, Semantic Understanding & Context Recognition, Language Comprehension, Language Production"
OSWorld,https://os-world.github.io/,https://arxiv.org/abs/2404.07972,"OSWorld evaluates autonomous computer-use agents that interact with a graphical operating system to complete realistic tasks (e.g., using apps, settings, files, and browsers). Success requires interpreting screenshots, navigating interfaces over multiple steps, and recovering from mistakes in long action sequences.","Visual Perception, Scene Understanding & Visual Reasoning, Visual Attention & Eye Movements, Sensorimotor Coordination, Planning, Adaptive Error Correction, Working Memory"
ARC-AGI,https://arcprize.org/arc-agi,https://arxiv.org/abs/1911.01547,ARC-AGI is an abstract reasoning benchmark where models infer latent rules from a few input-output grid examples and apply them to novel inputs. It emphasizes generalization to new tasks with minimal examples rather than memorized domain knowledge.,"Logical Reasoning, Cognitive Flexibility, Working Memory, Spatial Representation & Mapping, Planning"
Vending-Bench 2,https://andonlabs.com/evals/vending-bench-2,https://arxiv.org/abs/2502.15840,"Vending-Bench 2 measures long-horizon agent coherence and business decision-making in a simulated vending-machine enterprise over many steps. Agents must manage inventory, pricing, supplier interactions, and budgeting to maximize final returns while adapting to changing conditions.","Planning, Decision-making, Reward Mechanisms, Working Memory, Adaptive Error Correction"
CyberGym,https://www.cybergym.io/,https://arxiv.org/abs/2506.02548,"CyberGym evaluates cybersecurity agents on real-world software vulnerability tasks, including identifying known vulnerabilities and finding new ones at scale. It tests systematic investigation, hypothesis-driven debugging, and iterative exploitation/verification workflows in codebases and tooling environments.","Logical Reasoning, Planning, Adaptive Error Correction, Working Memory, Inhibitory Control"
SpreadsheetBench,https://spreadsheetbench.github.io/,https://arxiv.org/abs/2406.14991,"SpreadsheetBench measures the ability to understand, edit, and compute over complex spreadsheets, often requiring formula reasoning, structured data manipulation, and careful bookkeeping. Tasks reward precise transformations and consistent results across multiple interdependent cells and sheets.","Logical Reasoning, Working Memory, Planning, Adaptive Error Correction, Semantic Understanding & Context Recognition"
Humanity’s Last Exam,https://agi.safe.ai/,https://arxiv.org/abs/2501.14249,"Humanity’s Last Exam is a frontier-level academic and professional benchmark spanning many domains, with questions designed to be challenging even for strong models. It emphasizes broad expert knowledge, deep reasoning, and (in multimodal settings) integrating text with visual or other modalities.","Language Comprehension, Language Production, Logical Reasoning, Semantic Understanding & Context Recognition, Working Memory, Multisensory Integration"
GPQA Diamond,https://artificialanalysis.ai/evaluations/gpqa-diamond,https://arxiv.org/abs/2311.12022,"GPQA Diamond is a curated subset of graduate-level, “Google-proof” multiple-choice questions in science designed to resist shallow pattern-matching and retrieval shortcuts. It stresses careful reading, domain reasoning, and selecting among confusable alternatives.","Language Comprehension, Logical Reasoning, Working Memory, Semantic Understanding & Context Recognition, Decision-making"
MMMU-Pro,https://mmmu-benchmark.github.io/,https://arxiv.org/abs/2409.02813,MMMU-Pro is a high-difficulty multimodal benchmark that extends MMMU with more challenging expert-level questions requiring joint vision-and-language reasoning. Items often demand interpreting figures/diagrams and applying domain knowledge to reach a correct answer.,"Visual Perception, Scene Understanding & Visual Reasoning, Multisensory Integration, Logical Reasoning, Working Memory"
MathArena Apex,https://matharena.ai/?view=problem&comp=apex--apex_2025,https://arxiv.org/abs/2505.23281,"MathArena Apex evaluates advanced mathematical problem solving with an emphasis on difficult reasoning chains and accuracy under competition-style constraints. It stresses translating natural-language math problems into correct intermediate steps and final answers, often benefiting from rigorous verification.","Logical Reasoning, Working Memory, Planning, Adaptive Error Correction"
CharXiv Reasoning,https://charxiv.github.io/,https://arxiv.org/abs/2406.18521,"CharXiv Reasoning evaluates reasoning over scientific figures (commonly from research papers), requiring models to interpret charts/plots and answer questions that depend on quantitative and visual inference. It stresses linking visual evidence to precise textual conclusions and, in tool-augmented settings, structured analysis.","Visual Perception, Scene Understanding & Visual Reasoning, Multisensory Integration, Logical Reasoning, Working Memory, Attention"
OmniDocBench 1.5,https://github.com/opendatalab/OmniDocBench,https://arxiv.org/abs/2412.07626,"OmniDocBench 1.5 evaluates document understanding and OCR-like capabilities across diverse layouts, including text, formulas, tables, and reading order. It focuses on faithfully extracting structured content and preserving layout-dependent semantics in complex documents.","Visual Perception, Visual Attention & Eye Movements, Language Comprehension, Semantic Understanding & Context Recognition, Working Memory"
Video-MMMU,https://videommmu.github.io/,https://arxiv.org/abs/2501.13826,"Video-MMMU evaluates multimodal understanding and reasoning over video, where relevant evidence may appear across time. Tasks require integrating temporal visual cues with text prompts to answer questions that depend on events, sequences, and context.","Visual Perception, Scene Understanding & Visual Reasoning, Multisensory Integration, Working Memory, Attention, Cognitive Timing & Predictive Modeling"
LiveCodeBench Pro,https://livecodebenchpro.com/projects/livecodebench-pro/leaderboard,https://arxiv.org/abs/2506.11928,"LiveCodeBench Pro benchmarks coding performance on realistic programming problems, typically emphasizing correctness under a single-attempt evaluation regime. It stresses writing executable code, debugging via feedback, and maintaining consistency across multi-file or multi-step solutions.","Language Comprehension, Language Production, Logical Reasoning, Planning, Adaptive Error Correction, Working Memory"
FACTS Benchmark Suite,https://deepmind.google/blog/facts-benchmark-suite-systematically-evaluating-the-factuality-of-large-language-models/,https://arxiv.org/abs/2512.10791,"FACTS Benchmark Suite evaluates factuality and grounding behavior across multiple tasks intended to probe whether model outputs stay consistent with provided sources or established facts. It targets error modes such as hallucinations, unsupported claims, and overconfident fabrication in long-form responses.","Semantic Understanding & Context Recognition, Language Comprehension, Language Production, Inhibitory Control, Working Memory, Self-reflection"
Global PIQA,https://huggingface.co/datasets/mrlbenchmarks/global-piqa-nonparallel,https://arxiv.org/abs/2510.24081,"Global PIQA extends physical commonsense question answering to broader, multilingual settings, testing whether models can reason about everyday interactions with objects and environments. It emphasizes robust understanding of scenarios and selecting plausible actions or outcomes across languages.","Language Comprehension, Semantic Understanding & Context Recognition, Logical Reasoning, Decision-making"
MRCR v2 (8-needle),https://huggingface.co/datasets/openai/mrcr,https://arxiv.org/abs/2409.12640,"MRCR v2 (8-needle) evaluates long-context retrieval and multi-round coreference-like reasoning by hiding multiple similar “needle” items inside long “haystack” contexts. Models must locate and reproduce the correct referenced response, stressing precision under distractors and very long inputs.","Working Memory, Attention, Episodic Memory, Semantic Understanding & Context Recognition"
GDPval,https://openai.com/index/gdpval/,https://arxiv.org/abs/2510.04374,"GDPval measures performance on well-specified professional knowledge-work tasks spanning many occupations, judged against expert human outputs. Tasks often require producing concrete artifacts (e.g., plans, spreadsheets, presentations) with correct structure, constraints, and decision tradeoffs.","Planning, Decision-making, Language Production, Semantic Understanding & Context Recognition, Working Memory, Social Reasoning & Theory of Mind"
SWE-Lancer,https://openai.com/index/swe-lancer/,https://arxiv.org/abs/2502.12115,"SWE-Lancer evaluates real-world software engineering work framed as longer-horizon tasks that resemble professional development and maintenance. It emphasizes end-to-end problem solving: understanding requirements, modifying code correctly, and iterating with tests and tooling feedback.","Planning, Logical Reasoning, Adaptive Error Correction, Working Memory, Language Comprehension, Language Production"
Graphwalks,https://huggingface.co/datasets/openai/graphwalks,,"Graphwalks evaluates algorithmic reasoning over graph-structured data by asking models to perform constrained traversals and report results (e.g., reachable nodes, parent pointers). It stresses maintaining intermediate state over many steps and executing systematic graph-navigation procedures.","Spatial Representation & Mapping, Logical Reasoning, Working Memory, Planning, Attention"
Toolathon,https://toolathlon.xyz,https://arxiv.org/abs/2510.25726,"Toolathon benchmarks tool-using agents on multi-step tasks that require selecting, invoking, and composing tools reliably to achieve goals. It emphasizes correct tool choice, handling tool errors, and integrating tool outputs into a coherent final response.","Planning, Decision-making, Working Memory, Adaptive Error Correction, Language Comprehension, Language Production"
FrontierMath,https://epoch.ai/frontiermath,https://arxiv.org/abs/2411.04872,"FrontierMath evaluates advanced, expert-level mathematics beyond standard competition sets, designed to be challenging for frontier models and resistant to memorization. Problems require deep multi-step reasoning, careful abstraction, and (often) verification of intermediate results.","Logical Reasoning, Working Memory, Planning, Adaptive Error Correction, Cognitive Flexibility"
