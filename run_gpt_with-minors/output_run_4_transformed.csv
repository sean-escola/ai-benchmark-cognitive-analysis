Benchmark,Website,Paper,Description,Cognitive Functions,Max AI Tier
Terminal-Bench 2.0,https://www.tbench.ai/,,"Terminal-Bench 2.0 evaluates agentic coding by having models complete real command-line tasks (e.g., inspecting files, installing dependencies, running tests, and fixing issues) inside a sandboxed terminal. Success depends on iteratively choosing correct shell actions, interpreting outputs, and recovering from errors under realistic constraints.","L1: 
L2: Planning, Decision-making, Logical Reasoning, Working Memory, Adaptive Error Correction, Attention
L3: ",L2
BrowseComp,https://openai.com/index/browsecomp/,https://arxiv.org/abs/2504.12516,"BrowseComp measures deep-research performance where a model must answer difficult questions by searching and synthesizing evidence from a controlled web-style corpus/index. It stresses query formulation, evidence selection, and long-horizon reasoning across multiple retrieved sources rather than single-pass recall.","L1: Language Comprehension
L2: Planning, Decision-making, Semantic Understanding & Context Recognition, Working Memory, Attention
L3: ",L2
OSWorld,https://os-world.github.io/,https://arxiv.org/abs/2404.07972,"OSWorld evaluates multimodal computer-use agents that must operate a desktop-like environment to complete tasks across applications (navigation, typing, clicking, file operations, settings, etc.). It tests perception of UI state from screenshots, step-by-step planning, and robust execution with recovery from mistakes.","L1: Visual Perception
L2: Visual Attention & Eye Movements, Scene Understanding & Visual Reasoning, Planning, Decision-making, Adaptive Error Correction, Working Memory
L3: ",L2
ARC-AGI,https://arcprize.org/arc-agi,https://arxiv.org/abs/1911.01547,"ARC-AGI is a few-shot abstract reasoning benchmark based on colored grid transformation puzzles where the rule must be inferred from a handful of demonstrations. It targets generalization to novel patterns, compositional rule discovery, and flexible problem solving with minimal prior task-specific training.","L1: 
L2: Logical Reasoning, Working Memory, Spatial Representation & Mapping, Scene Understanding & Visual Reasoning, Attention
L3: Cognitive Flexibility",L3
Vending-Bench 2,https://andonlabs.com/evals/vending-bench-2,https://arxiv.org/abs/2502.15840,"Vending-Bench 2 evaluates long-horizon autonomous agency by simulating a year of running a vending-machine business, requiring thousands of decisions (pricing, inventory, supplier negotiation, etc.). It emphasizes sustained coherence, goal maintenance, and adapting strategy as conditions change over time.","L1: 
L2: Planning, Decision-making, Working Memory, Reward Mechanisms, Adaptive Error Correction
L3: Cognitive Timing & Predictive Modeling",L3
CyberGym,https://www.cybergym.io/,https://arxiv.org/abs/2506.02548,"CyberGym evaluates cybersecurity agents on tasks such as reproducing known vulnerabilities from high-level descriptions and discovering new vulnerabilities in real codebases. It stresses systematic investigation, hypothesis-driven testing, and iterative debugging in an adversarial, correctness-critical domain.","L1: 
L2: Logical Reasoning, Planning, Adaptive Error Correction, Working Memory, Attention, Semantic Understanding & Context Recognition
L3: ",L2
SpreadsheetBench,https://spreadsheetbench.github.io/,https://arxiv.org/abs/2406.14991,"SpreadsheetBench measures an agent’s ability to understand, edit, and compute with complex spreadsheets, often requiring multi-step transformations and formula reasoning. It evaluates whether models can maintain task context while manipulating structured data and verifying outputs programmatically.","L1: 
L2: Logical Reasoning, Planning, Working Memory, Adaptive Error Correction, Attention, Semantic Understanding & Context Recognition
L3: ",L2
Humanity’s Last Exam,https://agi.safe.ai/,https://arxiv.org/abs/2501.14249,"Humanity’s Last Exam is a frontier, multimodal benchmark spanning advanced academic and professional knowledge questions designed to be difficult to solve by memorization alone. It stresses integrating domain knowledge with multi-step reasoning, and (when tools are allowed) verifying claims via external evidence.","L1: Language Comprehension, Visual Perception
L2: Logical Reasoning, Semantic Understanding & Context Recognition, Working Memory, Planning
L3: ",L2
GPQA Diamond,https://artificialanalysis.ai/evaluations/gpqa-diamond,https://arxiv.org/abs/2311.12022,"GPQA Diamond is a high-quality subset of graduate-level, Google-resistant multiple-choice science questions where superficial pattern-matching tends to fail. It emphasizes careful reading, scientific reasoning across physics/chemistry/biology, and selecting among close distractors.","L1: Language Comprehension
L2: Logical Reasoning, Semantic Understanding & Context Recognition, Working Memory, Attention
L3: ",L2
MMMU-Pro,https://mmmu-benchmark.github.io/,https://arxiv.org/abs/2409.02813,"MMMU-Pro evaluates expert-level multimodal understanding across many disciplines using images (figures, diagrams, charts) paired with text questions and structured answer choices. It stresses aligning visual evidence with textual cues and performing multi-step reasoning grounded in the image content.","L1: Visual Perception, Language Comprehension
L2: Scene Understanding & Visual Reasoning, Multisensory Integration, Logical Reasoning, Working Memory, Attention
L3: ",L2
MathArena Apex,https://matharena.ai/?view=problem&comp=apex--apex_2025,https://arxiv.org/abs/2505.23281,"MathArena Apex is a competitive mathematics benchmark emphasizing difficult problem solving under standardized evaluation, often reflecting contest-style reasoning. It stresses constructing multi-step solution plans, maintaining intermediate results, and avoiding subtle algebraic or logical errors.","L1: 
L2: Logical Reasoning, Planning, Working Memory, Adaptive Error Correction, Attention
L3: ",L2
CharXiv Reasoning,https://charxiv.github.io/,https://arxiv.org/abs/2406.18521,CharXiv Reasoning evaluates whether models can answer questions that require interpreting scientific figures and chart-like visual artifacts commonly found in research papers. It stresses extracting quantitative/structural information from visuals and integrating it with domain text to justify conclusions.,"L1: Visual Perception
L2: Scene Understanding & Visual Reasoning, Multisensory Integration, Semantic Understanding & Context Recognition, Logical Reasoning, Working Memory, Attention
L3: ",L2
OmniDocBench 1.5,https://github.com/opendatalab/OmniDocBench,https://arxiv.org/abs/2412.07626,"OmniDocBench 1.5 evaluates document understanding and OCR-style extraction across heterogeneous layouts including text, tables, formulas, and reading order. It measures how well models perceive structured documents and produce faithful, correctly ordered reconstructions.","L1: Visual Perception
L2: Visual Attention & Eye Movements, Scene Understanding & Visual Reasoning, Semantic Understanding & Context Recognition, Working Memory, Attention
L3: ",L2
Video-MMMU,https://videommmu.github.io/,https://arxiv.org/abs/2501.13826,"Video-MMMU evaluates multimodal reasoning over video by requiring models to answer questions that depend on events, temporal changes, and contextual cues across frames. It stresses integrating observations across time and performing grounded reasoning about actions and causality.","L1: Visual Perception
L2: Scene Understanding & Visual Reasoning, Working Memory, Attention, Multisensory Integration
L3: Cognitive Timing & Predictive Modeling",L3
LiveCodeBench Pro,https://livecodebenchpro.com/projects/livecodebench-pro/leaderboard,https://arxiv.org/abs/2506.11928,"LiveCodeBench Pro measures coding ability on continuously updated programming tasks with standardized execution-based grading, aiming to reduce contamination. It stresses generating correct code, debugging failed runs, and iterating toward a passing solution under time/attempt constraints.","L1: Language Production
L2: Logical Reasoning, Planning, Working Memory, Adaptive Error Correction, Attention
L3: ",L2
FACTS Benchmark Suite,https://deepmind.google/blog/facts-benchmark-suite-systematically-evaluating-the-factuality-of-large-language-models/,https://arxiv.org/abs/2512.10791,"FACTS Benchmark Suite evaluates factuality and grounding by testing whether model outputs remain consistent with sources and avoid unsupported claims across varied settings. It targets reliability behaviors such as uncertainty expression, claim verification, and resisting hallucination when evidence is missing or conflicting.","L1: Language Comprehension
L2: Semantic Understanding & Context Recognition, Working Memory, Attention
L3: Inhibitory Control, Self-reflection",L3
Global PIQA,https://huggingface.co/datasets/mrlbenchmarks/global-piqa-nonparallel,https://arxiv.org/abs/2510.24081,"Global PIQA evaluates physical commonsense reasoning and everyday practicality across a globally diverse, multilingual setting. It stresses selecting plausible actions/outcomes in real-world scenarios where correct answers depend on intuitive physics and commonsense constraints.","L1: Language Comprehension
L2: Logical Reasoning, Semantic Understanding & Context Recognition, Attention
L3: Cognitive Flexibility",L3
MRCR v2 (8-needle),https://huggingface.co/datasets/openai/mrcr,https://arxiv.org/abs/2409.12640,"MRCR v2 (8-needle) tests long-context multi-round coreference by inserting repeated, similar “needle” requests into lengthy conversational “haystacks” and asking the model to retrieve the correct associated response. It stresses maintaining and accurately retrieving specific entities/relations under heavy interference.","L1: 
L2: Working Memory, Attention, Episodic Memory, Semantic Understanding & Context Recognition
L3: ",L2
GDPval,https://openai.com/index/gdpval/,https://arxiv.org/abs/2510.04374,"GDPval measures performance on well-specified professional knowledge work across many occupations using side-by-side human judging of produced artifacts (e.g., spreadsheets, slides, plans). It stresses following constraints, producing coherent deliverables, and making practical decisions that match real workplace objectives.","L1: Language Production
L2: Planning, Decision-making, Semantic Understanding & Context Recognition, Working Memory
L3: Social Reasoning & Theory of Mind",L3
SWE-Lancer,https://openai.com/index/swe-lancer/,https://arxiv.org/abs/2502.12115,"SWE-Lancer evaluates agentic software engineering on realistic repository-level tasks, emphasizing end-to-end patch creation and correctness under automated tests. It stresses decomposing ambiguous bug reports, navigating large codebases, and iteratively improving solutions based on tool feedback.","L1: 
L2: Planning, Decision-making, Logical Reasoning, Working Memory, Adaptive Error Correction, Attention
L3: ",L2
Graphwalks,https://huggingface.co/datasets/openai/graphwalks,,"Graphwalks evaluates long-context reasoning by encoding graph structures and asking models to perform operations like traversal, reachability, or parent/neighbor retrieval over large “in-context” graphs. It stresses precise multi-step symbol manipulation and resisting distraction from irrelevant nodes or edges.","L1: 
L2: Working Memory, Attention, Logical Reasoning, Spatial Representation & Mapping
L3: Cognitive Timing & Predictive Modeling",L3
Toolathon,https://toolathlon.xyz,https://arxiv.org/abs/2510.25726,"Toolathon evaluates general tool-use competence across diverse APIs and multi-step workflows, focusing on choosing the right tools, calling them correctly, and integrating results. It stresses robust execution in the perceive–plan–act loop, including recovery from tool errors and ambiguous intermediate outputs.","L1: Language Comprehension
L2: Planning, Decision-making, Adaptive Error Correction, Working Memory, Attention
L3: ",L2
FrontierMath,https://epoch.ai/frontiermath,https://arxiv.org/abs/2411.04872,"FrontierMath evaluates advanced mathematics at or beyond typical competition/research-adjacent difficulty, aiming to probe the frontier of formal quantitative reasoning. It stresses constructing long solution chains, maintaining invariants across steps, and verifying results (often with optional tool support).","L1: 
L2: Logical Reasoning, Planning, Working Memory, Adaptive Error Correction, Attention
L3: ",L2
